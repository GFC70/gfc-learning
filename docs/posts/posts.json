[
  {
    "path": "posts/2022-11-15-non-pivotpivots/",
    "title": "Making non-pivot tables summaries - Part 1",
    "description": "Sometimes people will mess up your pivot tables. Sometimes people will be terrified of pivot tables.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-11-15",
    "categories": [
      "Excel",
      "Pivot Tables",
      "CHOOSE, UNIQUE, SORT",
      "Spilled Arrays",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nThe Source Data\r\nSummary using a normal pivot table\r\nUsing CHOOSE and UNIQUE\r\nCHOOSE\r\nUNIQUE\r\n\r\nPutting it all together\r\nCreating our two formulas\r\nSorting the summary\r\n\r\n\r\nConclusion\r\n\r\nThe Problem\r\nI have worked with many project managers over the last 25 years. Many of them were very good at using MS Excel, some though were not. Two project managers spring to mind though. One was terrified of pivot tables. They insisted on not using them and would create workbooks with a sea of COUNTIFS and SUMIFS formulas. The other project manager loved pivot tables. Could not get enough of them. They would create pivot tables with practically every column available in a dataset, creating pivot tables that, if printed, could waste several trees of paper they were so large.\r\nThe Solution\r\nWith the recent addition of spilled arrays in MS Excel, creating summaries of data can be completed using just one formula. The advantage of using spilled arrays for summaries of data is that they updated automatically when new data is added to the source data unlike pivot tables, or summaries calculated through Power Query, that need to be refreshed via the Ribbon.\r\nThe Source Data\r\nThe source data we will be using for this example is shown below. A simple table of just 15 rows of data showing orders made by certain departments in a company, the name of the supplier, the order and ship date along with the amount of the order.\r\nSource DataThe data is saved in an MS Excel table with the name of Data on its own worksheet. We shall be adding a summary of the data by department showing how much each one spent on orders. Over the next several posts we shall expand on what the summary shows and the possible solutions.\r\nSummary using a normal pivot table\r\nUsing a normal pivot table for the source data, we are shown the summary below. We shall be recreating this summary using one formula.\r\nPivot Table SummaryUsing CHOOSE and UNIQUE\r\nA simple one cell summary formula can be created using the CHOOSE and UNIQUE formulas. But first lets look at the CHOOSE function in a little more details.\r\nCHOOSE\r\nThe MS Excel help for CHOOSE states:\r\n\r\nUses index_num to return a value from the list of value arguments. Use CHOOSE to select one of up to 254 values based on the index number. For example, if value1 through value7 are the days of the week, CHOOSE returns one of the days when a number between 1 and 7 is used as index_num.\r\n\r\nUsing the above description, we can create a formula that will identify the day of the week based on an input number.\r\nCHOOSE formulaThe CHOOSE function can also spilled values across columns. By using curly braces with a list of numbers in the first argument of the CHOOSE formula, we can add values across multiple columns in a row.\r\nCHOOSE formula spilling across many columnsAs shown in the image above, the three cells containing values in columns C, D and E have a blue border around. This indicates a spilled array.\r\nUNIQUE\r\nOne of the more powerful formulas to be added to MS Excel in recent years is the UNIQUE formula. As the name suggests, the formula will extract a list of unique values from a range of cells.\r\nUNIQUE formulaPutting it all together\r\nLooking at the standard pivot table solution shown above, we need to decide what we need to include in our summary of data.\r\nA list of unique department names from our source data table\r\nA SUMIF formula to calculate the total amount for each department\r\nCreating our two formulas\r\nFor our list of department names, we can use the formulas\r\n=UNIQUE(Data[Dept]) for the first column\r\n=SUMIF(Data[Dept], UNIQUE[Dept], Data[Amount]) for the second column\r\nUsing the CHOOSE formula that spills values across columns we can then create the formula below.\r\nSummary of DataWe get the same results, but with the department names in a different order.\r\nSorting the summary\r\nSorting the summary of data into the same order as the pivot table is as simple as wrapping our CHOOSE formula inside a SORT formula.\r\nSorted SummaryConclusion\r\nThis is a simple, but still powerful method to create a pivot table style summary using just formulas held in just one cell. This example could be expanded by amending the initial parameter in the CHOOSE function to show {1,2,3} and include a final column that shows the count of orders for each department.\r\nIn the next post, we will look at creating the same summary, but using two new formulas available in MS Excel - LET and SEQUENCE\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-15-non-pivotpivots/./pivot-table-summary.jpg",
    "last_modified": "2022-11-15T17:20:07+00:00",
    "input_file": "non-pivotpivots.knit.md"
  },
  {
    "path": "posts/2022-09-13-add-many-columns/",
    "title": "Adding Multiple Columns in Power Query",
    "description": "Adding multiple columns in Power Query can involve adding may steps. How about if it was possible to add many columns in one step?",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-09-13",
    "categories": [
      "Excel",
      "Power Query",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nThe Source Data\r\nAdding Records\r\nExpanding the Records\r\nUpdated M Code\r\n\r\nThe Problem with Records\r\nThe Solution\r\n\r\n\r\nConclusion\r\n\r\nThe Problem\r\nThere may be occasions when many columns are required to be added to a Power Query table. These new columns may be because of certain business rules, extracting information from an existing column or performing date and time calculations.\r\nThe Solution\r\nIn the post describing records we learnt that a power query can contain a record, or even a list of records, that contain multiple fields.\r\nRecords for each row in a table can be added via the normal Table.AddColumn function in Power Query. Many fields can be added to the record, with the required calculations, and then the record can be expanded to convert those record fields into new columns within the table.\r\nThe Source Data\r\nIn this example, we will be using a simple data set, stored in a table named Table1 on a worksheet within a workbook.\r\nSource Data in Table1The table is loaded in the usual manner into Power Query, via the From Table/Range button on the Data tab on the Excel Ribbon.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    )\r\nin\r\n    #\"Changed Type\"\r\n\r\nNote: This method does require manual typing of M Code in the Advanced Editor\r\n\r\nAdding Records\r\nTo add multiple columns, in this instance, we will add record fields for the year, month and month name from the Date column in the source table. As mentioned in the post describing records, records can be added by enclosing then in square brackets.\r\nOpen the Advanced Editor and add in the lines of M Code to create a new column containing a record for each row\r\n[\r\nName of Field = field value\r\n]\r\n\r\nUsing the Table.AddColumn function, we add the record for each row.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    ),\r\n    #\"Add Record\" = Table.AddColumn(#\"Changed Type\",\r\n        \"Record\",\r\n        each\r\n            [\r\n                Year = Date.Year([Date]),\r\n                Month = Date.Month([Date]),\r\n                Month Name = Date.MonthName([Date]),\r\n                Short Month Name = Text.Start(#\"Month Name\", 3)\r\n            ]\r\n    )\r\nin\r\n    #\"Add Record\"\r\n\r\nAs shown below, each row now has a Record in the new Record column.\r\nAdd RecordClicking in an empty area of a cell to the right of one of the Record items will show the field values in the record, as shown at the bottom of the image above.\r\nExpanding the Records\r\nNow each row has a record, the fields need to be expanded to create new columns in table. This is achieved by clicking the double arrows at the top of the Record column.\r\nExpand RecordClicking this double arrow button will show a pop-up with a list of the field available\r\nRecord Fields\r\nNote: It is suggested that the checkmark is removed for the Use original column name for prefix checkbox at the bottom of the pop-up\r\n\r\nOnce the OK button on the pop-up is clicked, the new columns will be added to the table.\r\nExpanded RecordUpdated M Code\r\nAfter the record column has been expanded, the extra M code, in the last #\"Expanded Record step has been added to the Power Query table.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    ),\r\n    #\"Add Record\" = Table.AddColumn(#\"Changed Type\",\r\n        \"Record\",\r\n        each\r\n            [\r\n                Year = Date.Year([Date]),\r\n                Month = Date.Month([Date]),\r\n                Month Name = Date.MonthName([Date]),\r\n                Short Month Name = Text.Start(#\"Month Name\", 3)\r\n            ]\r\n    ),\r\n    #\"Expanded Record\" = Table.ExpandRecordColumn(#\"Add Record\", \r\n        \"Record\", \r\n        {\"Year\", \"Month\", \"Month Name\", \"Short Month Name\"}, \r\n        {\"Year\", \"Month\", \"Month Name\", \"Short Month Name\"}\r\n    )\r\nin\r\n    #\"Expanded Record\"\r\n\r\n\r\nNote: The second list of field names in the #\"Expanded Record step is not actually required. The step will work fine without this. The second list is used if a new name is needed for the expanded record field.\r\n\r\nThe Problem with Records\r\nLooking at the column headers for the new columns, the icon shown is for the any data type icon of 123ABC. We would then need to set the correct data type for each of these new columns manually.\r\nColumn Data TypesThe Solution\r\nTo remove the need to manually set the data types for columns created from record fields, the initial M code that created the record can be amended. Adding another record within the step listing the data types solves this issue.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    ),\r\n    #\"Add Record\" = Table.AddColumn(#\"Changed Type\",\r\n        // Set the name of the new column\r\n        \"Record\",\r\n        \r\n        // Add fields to the recoed by wrapping in square brackets\r\n        each\r\n            [\r\n                Year = Date.Year([Date]),\r\n                Month = Date.Month([Date]),\r\n                Month Name = Date.MonthName([Date]),\r\n                \r\n                // Note that the Month Name field must be enclosed in a # and \"\" as the field is\r\n                // referenced in a standard function.\r\n                Short Month Name = Text.Start(#\"Month Name\", 3)\r\n            ],\r\n            \r\n            // Add a type record to assign data types to each field in the record\r\n            type\r\n            [\r\n                Year = Int64.Type,\r\n                Month = Int64.Type,\r\n                Month Name = text,\r\n                Short Month Name = text\r\n            ]\r\n    ),\r\n    #\"Expanded Record\" = Table.ExpandRecordColumn(#\"Add Record\", \r\n        // Name of the column to expand\r\n        \"Record\", \r\n        \r\n        // The fields to expand\r\n        {\"Year\", \"Month\", \"Month Name\", \"Short Month Name\"}\r\n    )\r\nin\r\n    #\"Expanded Record\"\r\n\r\n\r\nNote: The #“Expanded Record” step has had the second list of field names removed.\r\n\r\nOnce this new record listing the field data types have been added, the column data types now have the correct type assigned.\r\nColumn Data TypesConclusion\r\nThis method of adding multiple columns is quick, and once the structure is understood, a standard method for adding new columns, reducing the number of steps in a Power Query.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-09-13-add-many-columns/./source-data.jpg",
    "last_modified": "2022-09-13T18:22:12+01:00",
    "input_file": "add-many-columns.knit.md"
  },
  {
    "path": "posts/2022-08-31-presidential-campaigns/",
    "title": "Presidential Donations",
    "description": "How much were donations made to Presidential Campaigns?.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-30",
    "categories": [
      "R",
      "Tidy Tuesdays",
      "dplyr",
      "ggplot"
    ],
    "contents": "\r\n\r\nContents\r\nTidy Tuesday\r\nThe Data\r\nTidy the\r\ndata\r\nAdd\r\nvariables\r\nWhat’s in\r\nthe data?\r\n\r\nUS State\r\ndata\r\nCalculating the plot data\r\nJoining the\r\ndata\r\n\r\nBuilding the\r\nplot\r\nCreating plot labels\r\nMaking the final plot\r\nChange\r\nthose colours\r\nImproving the theme\r\n\r\nConclusion\r\n\r\nTidy Tuesday\r\nI decided to start posting items for the\r\nR for Data Science Tidy Tuesday project where data sets are\r\nreleased each Monday as part of the\r\nR4DS Online Learning Community. A quote from the home page\r\nstates -\r\n\r\nThe intent of Tidy Tuesday is to provide a safe and supportive forum\r\nfor individuals to practice their wrangling and data visualization\r\nskills independent of drawing conclusions. While we understand that the\r\ntwo are related, the focus of this practice is purely on building skills\r\nwith real-world data.\r\n\r\nThe Data\r\nI found the datasets used in this post by accident, while looking for\r\nanother item for a totally unrelated project, and thought this would be\r\na good starter for my first contribution.\r\nThe dataset is available here\r\nand is a zip file and the contents extracted to the data sub-folder.\r\n\r\nThe file is large, over 600Mb, so if you choose to use this data, be\r\nmindful of where you store the csv file.\r\n\r\n\r\n\r\n# Read data to a data frame\r\n\r\ndf <- read_csv(\"P00000001-ALL.csv\",\r\n               show_col_types = FALSE)\r\n\r\nstr(df)\r\n\r\nspec_tbl_df [4,084,074 × 16] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\r\n $ cmte_id          : chr [1:4084074] \"C00420224\" \"C00420224\" \"C00420224\" \"C00420224\" ...\r\n $ cand_id          : chr [1:4084074] \"P80002983\" \"P80002983\" \"P80002983\" \"P80002983\" ...\r\n $ cand_nm          : chr [1:4084074] \"Cox, John H\" \"Cox, John H\" \"Cox, John H\" \"Cox, John H\" ...\r\n $ contbr_nm        : chr [1:4084074] \"BROWN, CHARLENE\" \"KELLY, RAY\" \"CINGEL, KEITH\" \"DUNAWAY, JONATHON\" ...\r\n $ contbr_city      : chr [1:4084074] \"EAGLE RIVER\" \"HUNTSVILLE\" \"SEVERN\" \"DEATSVILLE\" ...\r\n $ contbr_st        : chr [1:4084074] \"AK\" \"AL\" \"AL\" \"AL\" ...\r\n $ contbr_zip       : chr [1:4084074] \"99577\" \"35801\" \"20999\" \"36022\" ...\r\n $ contbr_employer  : chr [1:4084074] NA \"ARKTECH\" \"SANTA CLAUS\" \"CSC\" ...\r\n $ contbr_occupation: chr [1:4084074] \"STUDENT\" \"RETIRED\" \"SNOWMAN\" \"TECHNICAL MANAGER\" ...\r\n $ contb_receipt_amt: num [1:4084074] 25 25 50 10 25 25 20 5 10 10 ...\r\n $ contb_receipt_dt : chr [1:4084074] \"01-MAR-07\" \"25-JAN-07\" \"17-MAY-07\" \"18-JAN-07\" ...\r\n $ receipt_desc     : chr [1:4084074] NA NA NA NA ...\r\n $ memo_cd          : chr [1:4084074] NA NA NA NA ...\r\n $ memo_text        : chr [1:4084074] NA NA NA NA ...\r\n $ form_tp          : chr [1:4084074] \"SA17A\" \"SA17A\" \"SA17A\" \"SA17A\" ...\r\n $ file_num         : num [1:4084074] 288757 288757 305408 288757 288757 ...\r\n - attr(*, \"spec\")=\r\n  .. cols(\r\n  ..   cmte_id = col_character(),\r\n  ..   cand_id = col_character(),\r\n  ..   cand_nm = col_character(),\r\n  ..   contbr_nm = col_character(),\r\n  ..   contbr_city = col_character(),\r\n  ..   contbr_st = col_character(),\r\n  ..   contbr_zip = col_character(),\r\n  ..   contbr_employer = col_character(),\r\n  ..   contbr_occupation = col_character(),\r\n  ..   contb_receipt_amt = col_double(),\r\n  ..   contb_receipt_dt = col_character(),\r\n  ..   receipt_desc = col_character(),\r\n  ..   memo_cd = col_character(),\r\n  ..   memo_text = col_character(),\r\n  ..   form_tp = col_character(),\r\n  ..   file_num = col_double()\r\n  .. )\r\n - attr(*, \"problems\")=<externalptr> \r\n\r\n16 variables are available in the data, but I will concentrate on the\r\ncontbr_st, contb_receipt_dt and\r\ncontb_receipt_amt variables to create a map showing which\r\nstates contributed the most dollars to campaigns. I’m not happy with\r\nthose variable names, so lets rename them.\r\nTidy the data\r\n\r\n\r\ndf <- df %>% \r\n  select(\r\n    city = contbr_city,\r\n    state_abb = contbr_st,\r\n    amount = contb_receipt_amt,\r\n    date = contb_receipt_dt\r\n  )\r\n\r\n\r\nAdd variables\r\nLet’s continue some basic tidying up of the data by ensuring the\r\ndate variable is recognised as a proper date values and add\r\na year variable.\r\n\r\n\r\ndf <- df %>% \r\n  mutate(date = dmy(date),\r\n         yr = as.numeric(year(date)))\r\n\r\n\r\nWhat’s in the data?\r\nWhat sort of spread of data do we have for each year in the data?\r\n\r\n\r\ndf %>% \r\n  group_by(yr) %>% \r\n  count(yr)\r\n\r\n# A tibble: 5 × 2\r\n# Groups:   yr [5]\r\n     yr       n\r\n  <dbl>   <int>\r\n1  2004       3\r\n2  2005     106\r\n3  2006    6089\r\n4  2007  691650\r\n5  2008 3386226\r\n\r\nIt looks like the first three years worth of the data contain low\r\nnumbers, so let’s exclude them from the data set - we may want to facet\r\nthe data later when we plot the map.\r\n\r\n\r\ndf <- df %>% \r\n  filter(date >= as.Date(\"2007-01-01\"))\r\n\r\n\r\nUS State data\r\nI had been aware of the built-in data sets within R and the various\r\nlibraries, but had never used them in a project. Let’s change that and\r\nget some data relating to the US States.\r\n\r\n\r\nstate_names <- data.frame(state_abb = state.abb,\r\n                          state_name = state.name)\r\n\r\nhead(state_names)\r\n\r\n  state_abb state_name\r\n1        AL    Alabama\r\n2        AK     Alaska\r\n3        AZ    Arizona\r\n4        AR   Arkansas\r\n5        CA California\r\n6        CO   Colorado\r\n\r\nLooking at the data_map(\"state\") data set that comes\r\nwith ggplot2, containing the longitude and latitude\r\nvariables for states, the region name is in lowercase, so let’s create\r\nthat data frame again, with a lower case state name\r\n\r\n\r\nstate_names <- data.frame(state_abb = state.abb,\r\n                          state_name = str_to_lower(state.name))\r\n\r\nhead(state_names)\r\n\r\n  state_abb state_name\r\n1        AL    alabama\r\n2        AK     alaska\r\n3        AZ    arizona\r\n4        AR   arkansas\r\n5        CA california\r\n6        CO   colorado\r\n\r\nCreate a new data frame containing the longitude and latitude\r\nvariables and join it to the state names\r\n\r\n\r\nmap_coords <- map_data(\"state\") %>% \r\n  inner_join(state_names, by = c(\"region\" = \"state_name\"))\r\n\r\nhead(map_coords)\r\n\r\n       long      lat group order  region subregion state_abb\r\n1 -87.46201 30.38968     1     1 alabama      <NA>        AL\r\n2 -87.48493 30.37249     1     2 alabama      <NA>        AL\r\n3 -87.52503 30.37249     1     3 alabama      <NA>        AL\r\n4 -87.53076 30.33239     1     4 alabama      <NA>        AL\r\n5 -87.57087 30.32665     1     5 alabama      <NA>        AL\r\n6 -87.58806 30.32665     1     6 alabama      <NA>        AL\r\n\r\nCalculating the plot data\r\nTo plot the data for amounts donated to the Presidential Campaigns,\r\nwe need the total amounts by state.\r\n\r\n\r\ndonations_by_state <- df %>% \r\n  group_by(state_abb, yr) %>% \r\n  summarise(total_amount = sum(amount), .groups = \"drop\")\r\n\r\nhead(donations_by_state)\r\n\r\n# A tibble: 6 × 3\r\n  state_abb    yr total_amount\r\n  <chr>     <dbl>        <dbl>\r\n1 -          2008          50 \r\n2 -1         2008        3100 \r\n3 0          2008       -4368.\r\n4 1          2008         376.\r\n5 60         2007         800 \r\n6 60         2008        1030 \r\n\r\nJoining the data\r\nWe can see from the donations_by_state data frame, we\r\nhave multiple rows with invalid state names.\r\n\r\n\r\nunique(donations_by_state$state_abb)\r\n\r\n  [1] \"-\"  \"-1\" \"0\"  \"1\"  \"60\" \"75\" \"AA\" \"AB\" \"AC\" \"AE\" \"AF\" \"AK\" \"AL\"\r\n [14] \"AM\" \"AN\" \"AP\" \"AR\" \"AS\" \"AU\" \"AZ\" \"BA\" \"BC\" \"BE\" \"BH\" \"BM\" \"BR\"\r\n [27] \"C\"  \"CA\" \"CH\" \"CN\" \"CO\" \"CT\" \"DC\" \"DE\" \"DF\" \"DI\" \"DJ\" \"EN\" \"ES\"\r\n [40] \"EU\" \"FF\" \"FI\" \"FL\" \"FM\" \"FR\" \"GA\" \"GE\" \"GH\" \"GR\" \"GU\" \"HE\" \"HI\"\r\n [53] \"HK\" \"HO\" \"HU\" \"IA\" \"ID\" \"IL\" \"IN\" \"IO\" \"IR\" \"IS\" \"IT\" \"JA\" \"JP\"\r\n [66] \"JT\" \"KE\" \"KS\" \"KT\" \"KY\" \"LA\" \"LN\" \"LO\" \"LU\" \"MA\" \"MB\" \"MD\" \"ME\"\r\n [79] \"MH\" \"MI\" \"ML\" \"MN\" \"MO\" \"MP\" \"MS\" \"MT\" \"MU\" \"MX\" \"MY\" \"N\"  \"N.\"\r\n [92] \"N/\" \"NC\" \"ND\" \"NE\" \"NH\" \"NJ\" \"NL\" \"NM\" \"NO\" \"NS\" \"NT\" \"NU\" \"NV\"\r\n[105] \"NY\" \"OC\" \"OH\" \"OK\" \"ON\" \"OR\" \"OT\" \"PA\" \"PE\" \"PO\" \"PR\" \"PW\" \"QB\"\r\n[118] \"QC\" \"QL\" \"QU\" \"RE\" \"RH\" \"RI\" \"RM\" \"SA\" \"SC\" \"SD\" \"SE\" \"SK\" \"SO\"\r\n[131] \"SP\" \"ST\" \"SU\" \"SW\" \"TA\" \"TE\" \"TH\" \"TK\" \"TN\" \"TO\" \"TP\" \"TR\" \"TU\"\r\n[144] \"TX\" \"TZ\" \"U.\" \"UK\" \"US\" \"UT\" \"VA\" \"VE\" \"VI\" \"VK\" \"VT\" \"WA\" \"WE\"\r\n[157] \"WI\" \"WV\" \"WY\" \"XX\" \"YT\" \"ZU\" \"ZZ\" NA  \r\n\r\nBy joining the data frame to the map_coords data frame,\r\nthese invalid rows will be removed.\r\n\r\n\r\nplot_data <- inner_join(x = map_coords, y = donations_by_state)\r\n\r\nhead(plot_data)\r\n\r\n       long      lat group order  region subregion state_abb   yr\r\n1 -87.46201 30.38968     1     1 alabama      <NA>        AL 2007\r\n2 -87.46201 30.38968     1     1 alabama      <NA>        AL 2008\r\n3 -87.48493 30.37249     1     2 alabama      <NA>        AL 2007\r\n4 -87.48493 30.37249     1     2 alabama      <NA>        AL 2008\r\n5 -87.52503 30.37249     1     3 alabama      <NA>        AL 2007\r\n6 -87.52503 30.37249     1     3 alabama      <NA>        AL 2008\r\n  total_amount\r\n1      2382083\r\n2      3661394\r\n3      2382083\r\n4      3661394\r\n5      2382083\r\n6      3661394\r\n\r\nBuilding the plot\r\nNow we have the data joined together, let’s make the first plot to\r\nsee what we have.\r\n\r\n\r\np <- ggplot(plot_data, aes(long, lat)) +\r\n  geom_polygon(aes(group = group, fill = total_amount),\r\n               colour = \"grey30\",\r\n               size = .2)\r\n\r\np\r\n\r\n\r\n\r\nI definitely do not like that standard blue for a continuous scale,\r\nwe will change that later on!\r\nWe can tell which are the top states making donations, but my being a\r\nBrit, I’m not always confident on which states are which (I know\r\nCalifornia, Texas and New York though!), so let’s find out the top 5\r\nstates making donations by looking at the\r\ndonations_by_state data frame again. We can use this later\r\nto create some descriptive text for the plot subtitle.\r\n\r\n\r\ntop_five_state_abb <- donations_by_state %>% \r\n  group_by(state_abb) %>% \r\n  summarise(total_amount = sum(total_amount)) %>% \r\n  arrange(desc(total_amount)) %>% \r\n  top_n(n = 5)\r\n\r\ntop_five_state_abb\r\n\r\n# A tibble: 5 × 2\r\n  state_abb total_amount\r\n  <chr>            <dbl>\r\n1 CA          177005057.\r\n2 NY          122472922.\r\n3 TX           65920709.\r\n4 FL           58941780.\r\n5 IL           54418090.\r\n\r\nCreating plot labels\r\nSo we can have a plot that explains what is being shown, we can\r\ncreate some text variables that will be used by the labs\r\nfunction when creating the plot.\r\n\r\n\r\nplot_title <- \"Which states donated the most for the US Presidential Campaigns?\"\r\n\r\nplot_caption <- \"Data Source: https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/pages/datasets-and-code/\"\r\n\r\n\r\nMaking a descriptive subtitle for the plot, we need to look back at\r\nsome of the earlier data frames and summarise the data a little\r\nfurther.\r\n\r\n\r\ntotal_donations <- inner_join(x = state_names, y = df) %>% \r\n  summarise(total_amount = sum(amount)) %>% pull(total_amount)\r\n\r\ntotal_donations\r\n\r\n[1] 995334194\r\n\r\nCreate the total amount donated by the top five states and calculate\r\nthe percentage of all donations.\r\n\r\n\r\ntop_five_amount <- sum(top_five_state_abb$total_amount)\r\n\r\ntop_five_pct <- percent(top_five_amount / total_donations, accuracy = .2)\r\n\r\ntop_five_amount <- dollar(top_five_amount, accuracy = .2, scale = 1e-6, suffix = \"m\")\r\n\r\ntotal_donations <- dollar(total_donations, accuracy = .2, scale = 1e-6, suffix = \"m\")\r\n\r\ntop_five_amount\r\n\r\n[1] \"$478.8m\"\r\n\r\ntop_five_pct\r\n\r\n[1] \"48.2%\"\r\n\r\ntotal_donations\r\n\r\n[1] \"$995.4m\"\r\n\r\nCreate a text string for the top five states donating.\r\n\r\n\r\ntop_five_states <- toString(top_five_state_abb %>% pull(state_abb))\r\n\r\n\r\nNow we have the amounts needed for the subtitle, lets make the text\r\nvariable, with a line break at the start to add some spacing.\r\n\r\n\r\nplot_subtitle <- glue::glue(\r\n  \"A total of {total_donations} was contributed from all states, with the top five states of {top_five_states}, contributing a total of {top_five_amount},<br />representing {top_five_pct} of all donations in 2007 & 2008\")\r\n\r\n\r\nMaking the final plot\r\n\r\n\r\np <- p +\r\n  labs(\r\n    title = plot_title,\r\n    subtitle = plot_subtitle,\r\n    caption = plot_caption,\r\n    fill = NULL # Remove legend title\r\n  )\r\n\r\np\r\n\r\n\r\n\r\nChange those colours\r\nAs I said previously, I do not like the standard blue colour that\r\ncomes with a continuous scale, let’s change and change the type of map\r\nprojection shown in the plot.\r\n\r\n\r\np <- p +\r\n  scale_fill_continuous(\r\n    low = '#FFF8DC',\r\n    high = '#8B1A1A',\r\n    labels = label_dollar(\r\n      scale = 1e-6,\r\n      suffix = \"m\",\r\n      accuracy = .2\r\n    )\r\n  ) +\r\n  coord_map(projection = \"mollweide\")\r\n\r\np\r\n\r\n\r\n\r\nImproving the theme\r\nLoad my preferred fonts for plot text and titles.\r\n\r\n\r\nfont_add_google(family = \"roboto-slab\", \"Roboto Slab\")\r\nfont_add_google(family = \"roboto-condensed\", \"Roboto Condensed\")\r\n\r\nshowtext_auto()\r\n\r\n\r\nVoid the theme by using theme_void\r\n\r\n\r\np <- p + theme_void()\r\n\r\np \r\n\r\n\r\n\r\nAs the amount of text for the title and subtitle overflow the plot\r\narea, we need to use the element_textbox_simple from the\r\nggtext package to allow for overflowing text and add all\r\nthe other plot theme elements.\r\n\r\n\r\np <- p +\r\n  theme(\r\n    text = element_text(family = \"roboto-condensed\", size = 22),\r\n    plot.margin = margin(rep(1, 4), unit = \"cm\"),\r\n    legend.direction = \"horizontal\",\r\n    legend.position = \"bottom\",\r\n    legend.key.height = unit(.8, units = \"lines\"),\r\n    legend.key.width = unit(3.5, units = \"lines\"),\r\n    legend.margin = margin(b = 1, unit = \"lines\"),\r\n    plot.title = element_text(\r\n      face = \"bold\",\r\n      size = 26,\r\n      family = \"roboto-slab\",\r\n      colour = \"#8B1A1A\"\r\n    ),\r\n    plot.title.position = \"plot\",\r\n    plot.subtitle = element_markdown(),\r\n    plot.caption = element_text(size = 14, hjust = 0, face = \"italic\"),\r\n    plot.caption.position = \"plot\",\r\n    panel.grid = element_line(\r\n      colour = \"grey30\",\r\n      size = .2,\r\n      linetype = \"dashed\"\r\n    )\r\n  )\r\n\r\np\r\n\r\n\r\n\r\nConclusion\r\nOverall, for a first attempt at using the maps data sets and plotting\r\ndata, I’m happy with the result.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-31-presidential-campaigns/./us_map.jpg",
    "last_modified": "2022-08-31T19:25:47+01:00",
    "input_file": "presidential-campaigns.knit.md"
  },
  {
    "path": "posts/2022-08-23-parameters-record/",
    "title": "Making parameters a record",
    "description": "Using a record to store your worksheet parameters.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-23",
    "categories": [
      "Excel",
      "Power Query",
      "Tips and Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nUsing\r\nRecords\r\nUsing a value from a record\r\nfield\r\nMultiple\r\nRecords\r\nUsing a value from a\r\nmulti-record list\r\nCreating the parameters\r\nrecord\r\n\r\nConclusion\r\n\r\nThe Problem\r\nIn the last\r\npost we learnt how to create Power Query parameters from named\r\nranges on a worksheet using just one line of M Code. This method is\r\ngreat if the set of queries only have a few parameters that would be\r\nreferences, but what if there were many parameters? There is the\r\npossibility that with a large number of parameters, keep track of them\r\nall in the Power Query Editor could cause issues. What if we could store\r\nthem all in one query?\r\nThe Solution\r\nUsing Records\r\nA record can be thought of as a single vertical column of data. Think\r\nof it as one row from a table of data, but shown vertically. Records in\r\nPower Query can be in tables, lists and can also be created manually if\r\nneeded.\r\nThe structure of a record requires a name for a field within the\r\nrecord and a value to store within that field. All fields that are\r\nwithin a record must be wrapped in square brackets.\r\n[\r\n    Name = \"Mickey Mouse\",\r\n    Role = \"Cartoon Mouse\",\r\n    Name of Spouse = \"Minnie Mouse\"\r\n]\r\nA single record\r\nNote - A field within a record can contain multiple spaces without\r\nthe need to wrap the name within a #“” in a normal power query. Values\r\nassigned to fields must have the value enclosed in quotes if spaces are\r\nin the value.\r\n\r\nUsing a value from a record\r\nfield\r\nTo refer to a field within a record, the name of the query and the\r\nfield name can be used using the syntax of\r\nQueryName[FieldName]\r\nFor the example above, if the query name was Mickey, to\r\nextract each of the values, the M code would be\r\nMickey[Name]\r\n\r\nMickey[Role]\r\n\r\nMickey[Name of Spouse]\r\nMultiple Records\r\nTo create multiple records within one query, wrap the records within\r\ncurly brackets. Using curly brackets converts this query to a list.\r\n\r\nNote: Each record must contain the same field names, although a field\r\ncan contain a null value.\r\n\r\n{\r\n    [\r\n        Name = \"Mickey Mouse\",\r\n        Role = \"Cartoon Mouse\",\r\n        Name of Spouse = \"Minnie Mouse\"\r\n    ],\r\n    [\r\n        Name = \"Donald Duck\",\r\n        Role = \"Cartoon Duck\",\r\n        Name of Spouse = \"Daisy Duck\"\r\n    ]\r\n}\r\nA list of recordsUsing a value from a\r\nmulti-record list\r\nAs Power Query uses zero-based counting, the first record in the\r\nexample above, would have a zero index, the second record would have an\r\nindex of 1, and so on. To extract a value from the multi-record list,\r\nuse the syntax QueryName{Index}[FieldName]\r\nFor the example above, if the query name was Characters,\r\nto extract each of the values for the name fields, the M code would\r\nbe\r\nCharacters{0}[Name]\r\n\r\nCharacters{1}[Name]\r\n\r\nExtracting name from first\r\nrecordCreating the parameters\r\nrecord\r\nUsing the methods above, we can create our record for storing the\r\nparameters by wrapping the three items in square brackets and create a\r\nmulti-field single record query named FileParameters\r\n[\r\n    DataPath = Excel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1] \r\n    meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false],\r\n    \r\n    MainSource = Excel.CurrentWorkbook(){[Name=\"Main_Source\"]}[Content]{0}[Column1] \r\n    meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false],\r\n    \r\n    Lookups = Excel.CurrentWorkbook(){[Name=\"Lookups\"]}[Content]{0}[Column1] \r\n    meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\n]\r\n\r\n\r\nNote: There is no need for an = sign at the start of a query\r\ncontaining a record.\r\n\r\nTo use the parameters above in a query to load data, we call the\r\nFileParameters query and use the relevant fields to extract\r\nthe required data.\r\nlet\r\n    Source = Csv.Document(\r\n        File.Contents(\r\n            FileParameters[DataPath] & FileParameters[MainSource]\r\n            ),\r\n        [Delimiter=\",\", Columns=4, Encoding=1252, QuoteStyle=QuoteStyle.None]\r\n    )\r\nin\r\n    Source\r\n\r\nConclusion\r\nUsing a parameters query to store values from named ranges on a\r\nworksheet may take a little effort to initially set-up, but I believe\r\nthat outweighs the need to remember how to refer to or look up the\r\nsyntax to extract a named range each time one is needed to be used.\r\nI have also seen vast improvements in the speed of loading data from\r\nworkbooks, either saved locally or on SharePoint sites, from several\r\nminutes to just a few seconds.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-23-parameters-record/./parameters-record-overview.jpg",
    "last_modified": "2022-08-23T16:13:25+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-15-how-to-parameterise/",
    "title": "How to parameterise",
    "description": "There are many ways to use parameters in Power Query. Here's my favourite method",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-15",
    "categories": [
      "Excel",
      "Power Query",
      "Tips and Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nTL;DR\r\nCreating a Named Range\r\nExtracting the Named Range\r\nvalue\r\nCreate the Power Query\r\nParameter\r\nUsing\r\nthe Parameter\r\n\r\nConclusion\r\n\r\nThe Problem\r\nWhen I first started using Power Query, in one of its very early\r\nversions, file paths to data sources were often hard-coded into each\r\nquery. This would cause issues if the workbook was sent to another user\r\nand the data source was in a folder on my file structure, obviously, the\r\nother user would not have access to my folders!\r\nThe method of using filenames then changed to using a table on a\r\nworksheet, often named Parameters that would list all the\r\nfile paths for all data sources used by Power Query. This method worked\r\nfine until one monster of a workbook was developed. With 17 or so data\r\nsources from a variety of locations, both shared network folders and\r\nSharePoint Document Libraries, the process began to get slower and\r\nslower.\r\nTo extract a file path and name from the Parameters\r\nworksheet would take an age to load in the Power Query Editor window\r\njust to make a change to the query or to refresh it when in the editor\r\nwindow.\r\nA new method was needed.\r\nThe Solution\r\nI had used the New Parameter method from the Power Query\r\nEditor window to add a value to an item, but others using the workbook\r\nare not always confident in using the editor. The solution was to use\r\nExcel Named Ranges and call them in one line of M code.\r\nTL;DR\r\nCreate a new blank query\r\nRename the query to the required name\r\nOpen the Advanced Editor\r\nRemove the M code shown\r\nPaste in the line below, replacing the Data_Path value\r\nto the name of your named range\r\nExcel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1] meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\nClick OK\r\nCreating a Named Range\r\nA named range in Excel can be a single cell or any number of cells\r\nthat have a name assigned to them. Named ranges can be accessed from the\r\ndrop down box to the left of the formula bar.\r\nNamed Range Drop Down ListFor this example, I have created three named ranges, one for each\r\nfile and the data path those files are saved in.\r\nExanple FilesEach cell has been named based on the value in column B of the\r\nworksheet. Spaces have been replaced with underscores where they\r\nexist.\r\nTo create a named range quickly, hit the\r\nCTRL + SHIFT + F3 keys and a dialog box will be shown\r\nasking where the name for the range is. In the example shown, both cells\r\nB2 and C2 have been selected, with cell B2 containing the name to assign\r\nto cell C3\r\nCreate Names from SelectionIf all looks OK in the Create Names from Selection\r\ndialog box, click OK. Selecting cell C3 will shown\r\nData_Path in the Named Range drop down list as shown in the\r\nfirst image above.\r\nExtracting the Named Range\r\nvalue\r\nAlthough I mentioned above that the parameter can be created in one\r\nline of M code, we’ll look at the process of extracting named ranges\r\nfrom a worksheet.\r\n\r\nThe steps in the image above, produce these lines of M code.\r\nlet\r\n    Source = Excel.CurrentWorkbook(),\r\n    #\"Filtered Rows\" = Table.SelectRows(Source, each ([Name] = \"Data_Path\")),\r\n    #\"Removed Other Columns\" = Table.SelectColumns(#\"Filtered Rows\",{\"Content\"}),\r\n    #\"Expanded Content\" = Table.ExpandTableColumn(#\"Removed Other Columns\", \"Content\", {\"Column1\"}, {\"Column1\"}),\r\n    Column1 = #\"Expanded Content\"{0}[Column1]\r\nin\r\n    Column1\r\nWhat does this code do?\r\nThis will list all the named ranges, sheets names and tables.\r\nSource = Excel.CurrentWorkbook()\r\nThis step will filter the list of named ranges to the required\r\nvalue.\r\n#\"Filtered Rows\" = Table.SelectRows(Source, each ([Name] = \"Data_Path\")),\r\nRemoving the Name column from the table shown in the editor window,\r\nby selecting just the Content column.\r\n#\"Removed Other Columns\" = Table.SelectColumns(#\"Filtered Rows\",{\"Content\"})\r\nThis step expands the content in the row for the content column.\r\nClicking in a white space area, next to the word Table will\r\ngive a preview of the value(s) stored in that table.\r\n#\"Expanded Content\" = Table.ExpandTableColumn(#\"Removed Other Columns\", \"Content\", {\"Column1\"}, {\"Column1\"})\r\nTable ContentsColumn1 = #\"Expanded Content\"{0}[Column1]\r\nBy right-clicking in a white space area next to the word\r\nTable and select Drill Down to get to the\r\nvalue of the named range.\r\nA lot of steps to get to one value.\r\nCreate the Power Query\r\nParameter\r\nThe important parts of the M code above, that are needed to use as a\r\none line query are:\r\nExcel.CurrentWorkbook()\r\n\r\n[Name] = \"Data_Path\"\r\n\r\n\"Content\"\r\n\r\n{0}[Column1]\r\n\r\nThese values can be combined into one line:\r\nExcel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1]\r\nThe only part now needed is some meta data that lets Power Query know\r\nthat this query is actually a parameter.\r\nmeta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\nCombining these two sets of M code to create the final result.\r\nExcel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1] meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\nUsing the Parameter\r\nTo use the parameter in a query, just replace any previously\r\nhard-coded path or file name. As the query contains the meta data values\r\nat the end, the value will also be available in any drop-down lists for\r\nparameters.\r\nUsing a parameterConclusion\r\nThis method of using named ranges from worksheets has reduced\r\ndevelopment time when creating automated excel workbooks.\r\nThere is also a method for storing many parameters in one query, but\r\nthat can be a post for another day.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-15-how-to-parameterise/./CreateParameter1.gif",
    "last_modified": "2022-08-15T18:05:02+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-14-2022-08-14-pq-zoom/",
    "title": "Zooming",
    "description": "Zooming the Power Query Editor Window",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-14",
    "categories": [
      "Excel",
      "Power Query",
      "Tips and Tricks"
    ],
    "contents": "\r\nA tip that is often forgotten about is how to zoom in and out when\r\nusing the Power Query Editor. The text showing the data table can appear\r\nsmall to those with visual difficulties. Even for those without\r\ndifficulties, the size of the text can prove problematic at times.\r\nTo increase the size of the text shown in the editor window, use the\r\nkey combinations of\r\nCTRL SHIFT + to zoom in\r\nCTRL SHIFT - to zoom out\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-14-2022-08-14-pq-zoom/./zoom.gif",
    "last_modified": "2022-08-14T16:19:56+01:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to GFC Learning",
    "description": "Welcome to my blog, GFC Learning.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-14",
    "categories": [
      "Welcome",
      "Excel",
      "Power Query",
      "Power Pivot",
      "DAX",
      "VBA",
      "R",
      "Tidyverse",
      "ggplot"
    ],
    "contents": "\r\nExcel question?\r\nProblems with Power Query?\r\nHere I will try to answer some of the more obscure questions you may\r\nhave about using MS Excel and Power Query, PowerPivot, DAX and using the\r\nExcel Data Model and throw some Visual Basic for Applications (VBA) into\r\nthe mix.\r\n\r\n\r\n\r\nI have also recently been learning the programming language\r\nR. There will also be posts using R showing\r\nhow I have been using it for data transformations and data\r\nvisulisations.\r\n\r\nThis website was built completely in R using the distill\r\npackage. Distill is a publication format for scientific and technical\r\nwriting, native to the web.\r\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/welcome/./logo.jpg",
    "last_modified": "2022-08-14T16:17:40+01:00",
    "input_file": {}
  }
]
