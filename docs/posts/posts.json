[
  {
    "path": "posts/2023-03-14-covid-visualisation-part-two/",
    "title": "Visualising UK Covid-19 Data - Part 2",
    "description": "A recent news report suggested that Covid-19 cases in England and Wales are increasing once more. Here we look at data for 2023.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2023-03-14",
    "categories": [
      "R",
      "ggplot",
      "Data Analysis",
      "Data Visualisation",
      "Charting",
      "Covid-19"
    ],
    "contents": "\r\n\r\nContents\r\nOverview\r\nLoad Data\r\nTransform Data\r\nTop Ten Areas\r\n\r\nCreate Plot\r\nCreate Plot Labels\r\nCreate Colour Palette\r\nFiltering for North East England\r\n\r\nConclusion\r\n\r\nOverview\r\nIn part one we downloaded data from the UK Government’s Health Security Agency Covid-19 Dashboard website.\r\nLoad Data\r\nThe data is now only updated weekly, so a CSV file with the data was saved to remove the need for daily downloads of data.\r\n\r\n\r\ndf <- read_csv(\"all_areas.csv\")\r\n\r\n\r\n\r\n# A tibble: 6 × 5\r\n  area_code area_name                 date       new_cases_b…¹ country\r\n  <chr>     <chr>                     <date>             <dbl> <chr>  \r\n1 E06000003 Redcar and Cleveland      2023-03-08             5 England\r\n2 E06000014 York                      2023-03-08            14 England\r\n3 E06000050 Cheshire West and Chester 2023-03-08            18 England\r\n4 E08000001 Bolton                    2023-03-08             7 England\r\n5 E08000016 Barnsley                  2023-03-08            14 England\r\n6 E08000031 Wolverhampton             2023-03-08            12 England\r\n# … with abbreviated variable name ¹​new_cases_by_specimen_date\r\n\r\nTransform Data\r\nTop Ten Areas\r\nFor the plots that will be created for this post, we need to look for the top ten areas, or counties, in England and Wales, so we can plot the data for 2023.\r\n\r\n\r\ntop_ten_all_areas_df <- df %>%\r\n  \r\n  # Filter data for just 2023\r\n  filter(date >= as.Date(\"2023-01-01\")) %>%\r\n  \r\n  # Group by area_name variable\r\n  group_by(area_name) %>%\r\n  \r\n  # Calculate total number of cases by area_name\r\n  summarise(cases = sum(new_cases_by_specimen_date)) %>%\r\n  \r\n  # Sort in descending order\r\n  arrange(-cases) %>%\r\n  \r\n  # Get the top ten items\r\n  top_n(10) \r\n\r\n\r\n\r\n# A tibble: 10 × 2\r\n   area_name       cases\r\n   <chr>           <dbl>\r\n 1 Hampshire        6150\r\n 2 Kent             5570\r\n 3 Essex            5543\r\n 4 Lancashire       4804\r\n 5 Hertfordshire    4449\r\n 6 Surrey           4377\r\n 7 Norfolk          3777\r\n 8 Staffordshire    3659\r\n 9 Devon            3605\r\n10 Nottinghamshire  3501\r\n\r\nCreate Plot\r\nCreate Plot Labels\r\nWe can now add some labels with some descriptive text explaining the chart to the viewer.\r\n\r\n\r\n# Calculate the total number of cases for use in plot subtitle\r\ntotal_cases <- comma(sum(top_ten_all_areas_df$cases))\r\n\r\ntitle_text <- \"How many new cases of Covid-19 have been submitted?\"\r\n\r\nsubtitle_text <- paste(\r\n      \"Top 10 areas with a seven day rolling average since 1st January 2023. \r\n      These areas have submitted a total of\",\r\n      total_cases,\r\n      \"cases during 2023\"\r\n    )\r\n\r\ncaption_text <- \"Source: UK Health Security Agency at https://coronavirus.data.gov.uk/\"\r\n\r\n\r\nCreate Colour Palette\r\nCreate a new palette of colours using the colorspace package to remove the standard ggplot2 colour palette.\r\n\r\n\r\n# Create colour palette using the RedOr (Red-Orange) palette\r\npal <- colorspace::sequential_hcl(n = 10, palette = \"redor\")\r\n\r\n\r\nNow we have the data loaded, labels created and a new colour palette, let’s create our plot. For this plot we shall use the rollmean function from the zoo package to create a 7 day rolling average to use in the plot.\r\n\r\n\r\ndf %>%\r\n  \r\n  # Filter for this year's data and for areas found in the\r\n  # top_ten_all_areas_df tibble\r\n  filter(date >= as.Date(\"2023-01-01\"),\r\n         area_name %in% top_ten_all_areas_df$area_name) %>%\r\n  \r\n  # Mutate the area_name to a factor and reorder by the order\r\n  # in the top_ten_all_areas_df\r\n  mutate(area_name = area_name %>%\r\n           fct_reorder(new_cases_by_specimen_date, sum) %>%\r\n           fct_rev()\r\n  ) %>%\r\n  \r\n  # Group by area_name and date\r\n  group_by(area_name, date) %>%\r\n  \r\n  # Calculate the total number of cases\r\n  summarise(cases = sum(new_cases_by_specimen_date)) %>%\r\n  \r\n  # Calculate the rolling seven day average using the rollmean function\r\n  mutate(roll_seven =\r\n         rollmean(cases, k = 7, na.pad = TRUE, align = \"right\", fill = NA)\r\n  ) %>%\r\n  \r\n  ## Create initial plot\r\n  ggplot(aes(date, roll_seven)) +\r\n  \r\n  # Add an area geom with transparency of 45%\r\n  geom_area(aes(fill = area_name),\r\n            show.legend = FALSE,\r\n            alpha = .15) +\r\n  \r\n  # Add a line geom, which will show at the top of the geom_area\r\n  geom_line(aes(colour = area_name),\r\n            show.legend = FALSE,\r\n            linewidth = .9) +\r\n  \r\n  # Assign colours from the custom palette for the geom_lines\r\n  scale_colour_manual(values = pal) +\r\n  \r\n  # Assign colours from the custom palette to the geom_areas\r\n  scale_fill_manual(values = pal) +\r\n  \r\n  # Amend x axis labels and limits\r\n  scale_x_date(labels = label_date_short(),\r\n               limits = as.Date(c((\"2023-01-03\"), NA))) +\r\n  \r\n  # Facet data by area_name with two rows of five charts\r\n  facet_wrap( ~ area_name, nrow = 2) +\r\n  \r\n  # Amend the theme\r\n  theme(\r\n    panel.grid.major.y = element_line(colour = \"grey90\"),\r\n    panel.spacing.x = unit(0.2, \"cm\"),\r\n    strip.text = element_text(hjust = 0, face = \"bold\"),\r\n    axis.title.y = element_blank(),\r\n    axis.title.x = element_blank(),\r\n    axis.text.x = element_text(size = 8)\r\n  ) +\r\n  \r\n  # Add plot labels\r\n  labs(\r\n    title = title_text,\r\n    subtitle = subtitle_text,\r\n    caption = caption_text\r\n  )\r\n\r\n\r\n\r\n\r\n\r\nFigure 1: A facet plot of the Top Ten Areas in England & Wales\r\n\r\n\r\n\r\nFiltering for North East England\r\nTo filter the data for the area of the UK where I live, we can filter the data on the initial loading. First, create a vector of area names in North East England\r\n\r\n\r\n# Create list of areas to use in the filter\r\nareas <- c(\r\n  \"Hartlepool\",\"Middlesbrough\",\"Redcar and Cleveland\",\r\n  \"Stockton-on-Tees\",\"Darlington\",\"County Durham\",\r\n  \"Northumberland\",\"Newcastle upon Tyne\",\"North Tyneside\",\r\n  \"South Tyneside\",\"Sunderland\",\"Gateshead\"\r\n  )\r\n\r\n\r\nApply the filter when the data is initially loaded.\r\n\r\n\r\n\r\nThe steps outlined in the previous sections can then be followed once more to create the plot below.\r\n\r\n\r\n\r\nFigure 2: A facet plot of the Top Ten Areas in North East England\r\n\r\n\r\n\r\nConclusion\r\nIn this post we looked at the top ten areas in both England & Wales as a whole and the in the North East England.\r\nIn the next post, data will be shown in a choropleth map showing the areas of England and Wales by the number of Covid-19 cases.\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-03-14-covid-visualisation-part-two/top_ten_rolling_mean.png",
    "last_modified": "2023-03-14T17:38:30+00:00",
    "input_file": "covid-visualisation-part-two.knit.md"
  },
  {
    "path": "posts/2023-03-02-covid-visualisationpart-one/",
    "title": "Visualising UK Covid-19 Data - Part One",
    "description": "A recent news report suggested that Covid-19 cases in England and Wales are increasing once more.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2023-03-02",
    "categories": [
      "R",
      "ggplot",
      "Data Analysis",
      "Data Visualisation",
      "Charting",
      "Covid-19"
    ],
    "contents": "\r\n\r\nContents\r\nOverview\r\nDownloading Covid-19 Data\r\nDownload URL\r\n\r\nInitial Analysis and Plot\r\nA better plot\r\nSummarise the data\r\nBasic column plot\r\nChanging the layout and palette\r\nAdding labels\r\nCreate the final plot\r\n\r\nConclusion\r\n\r\nOverview\r\nA recent news report, I cannot remember where, suggested that the number of Covid-19 cases in England and Wales have been increasing since the start of February 2023.\r\nDuring the first Covid-19 lockdown in the UK, I started to download the UK government’s Covid-19 datasets to expand my knowledge and skills to use the ggplot2 package to create visualisations of the data.\r\nThe data available, and method of downloading the data has expanded considerable since then and is now available via a URL rather than using an API and custom functions.\r\nDownloading Covid-19 Data\r\nPreviously, a package was available to download data. I had used it on several occasions but found it slow and sometimes the data was not consistent or was missing values.\r\nLooking again at the UK government’s Covid-19 Dashboard, an option is available to create a custom URL that will create a CSV file containing the required data.\r\nDownload URL\r\nUsing the link above, searching through the many metrics that are available, I settled on using the metric named newCasesBySpecimenDate. The Metrics Documentation for this item states:\r\n\r\nCOVID-19 cases are identified by taking specimens from people and testing them for the SARS-CoV-2 virus. If the test is positive, this is a case.\r\n\r\nUsing the URL built on the download page, we can obtain the data using read_csv from the readr package.\r\n\r\n\r\n# Download URL\r\nurl <- \"https://api.coronavirus.data.gov.uk/v2/data?\r\nareaType=utla&metric=newCasesBySpecimenDate&format=csv\"\r\n\r\n\r\ndf <- read_csv(url) %>% \r\n  # clean column names\r\n  janitor::clean_names() %>%\r\n  # add new variable based on first letter of area_code\r\n  mutate(country = if_else(substr(area_code, 1, 1) == \"E\", \r\n                           \"England\", \r\n                           \"Wales\")) %>% \r\n  # drop column listing government area type\r\n  select(-3)\r\n\r\n# Write to CSV file\r\nwrite_csv(df, file = \"all_areas.csv\")\r\n\r\n\r\n\r\n# A tibble: 6 × 5\r\n  area_code area_name                 date       new_cases_b…¹ country\r\n  <chr>     <chr>                     <date>             <dbl> <chr>  \r\n1 E06000003 Redcar and Cleveland      2023-03-08             5 England\r\n2 E06000014 York                      2023-03-08            14 England\r\n3 E06000050 Cheshire West and Chester 2023-03-08            18 England\r\n4 E08000001 Bolton                    2023-03-08             7 England\r\n5 E08000016 Barnsley                  2023-03-08            14 England\r\n6 E08000031 Wolverhampton             2023-03-08            12 England\r\n# … with abbreviated variable name ¹​new_cases_by_specimen_date\r\n\r\nInitial Analysis and Plot\r\nWhat sort of data do we have in the dataset?\r\n\r\nspc_tbl_ [232,016 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\r\n $ area_code                 : chr [1:232016] \"E06000003\" \"E06000014\" \"E06000050\" \"E08000001\" ...\r\n $ area_name                 : chr [1:232016] \"Redcar and Cleveland\" \"York\" \"Cheshire West and Chester\" \"Bolton\" ...\r\n $ date                      : Date[1:232016], format: \"2023-03-08\" ...\r\n $ new_cases_by_specimen_date: num [1:232016] 5 14 18 7 14 12 23 12 3 5 ...\r\n $ country                   : chr [1:232016] \"England\" \"England\" \"England\" \"England\" ...\r\n - attr(*, \"spec\")=\r\n  .. cols(\r\n  ..   area_code = col_character(),\r\n  ..   area_name = col_character(),\r\n  ..   date = col_date(format = \"\"),\r\n  ..   new_cases_by_specimen_date = col_double(),\r\n  ..   country = col_character()\r\n  .. )\r\n - attr(*, \"problems\")=<externalptr> \r\n  area_code          area_name              date           \r\n Length:232016      Length:232016      Min.   :2020-01-30  \r\n Class :character   Class :character   1st Qu.:2020-11-30  \r\n Mode  :character   Mode  :character   Median :2021-08-28  \r\n                                       Mean   :2021-08-29  \r\n                                       3rd Qu.:2022-05-26  \r\n                                       Max.   :2023-03-08  \r\n new_cases_by_specimen_date   country         \r\n Min.   :   0.0             Length:232016     \r\n 1st Qu.:   9.0             Class :character  \r\n Median :  31.0             Mode  :character  \r\n Mean   : 104.2                               \r\n 3rd Qu.: 108.0                               \r\n Max.   :6865.0                               \r\n\r\nLet’s do a quick plot of the data for whole period and all areas.\r\n\r\n\r\n# Basic line ggplot of all data\r\ndf %>%\r\n  ggplot(aes(date, new_cases_by_specimen_date)) +\r\n  geom_line()\r\n\r\n\r\n\r\n\r\n\r\nFigure 1: A simple line plot\r\n\r\n\r\n\r\nThere is definitely a peak of cases at the end of 2021 or the start of 2022. Let’s tidy the data and change the plot type to a column chart so we can see a clearer picture of the data.\r\nA better plot\r\nTo so there is not so much data included in a plot, let’s add some new variables for year and month and group the data by those values to obtain a clearer view of the data.\r\nSummarise the data\r\n\r\n\r\nall_areas_df <- df %>%\r\n  # Add yr, month labels\r\n  mutate(yr = year(date) %>% as.factor(),\r\n         mth = month(date)\r\n         ) %>%\r\n  # Group data\r\n  group_by(yr, mth) %>%\r\n  # Calculate total cases\r\n  summarise(cases = sum(new_cases_by_specimen_date), .groups = \"drop\")\r\n\r\n\r\n\r\nRows: 39\r\nColumns: 3\r\n$ yr    <fct> 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, …\r\n$ mth   <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, …\r\n$ cases <dbl> 1, 57, 36486, 132491, 78120, 27923, 20589, 34239, 1491…\r\n\r\nBasic column plot\r\n\r\n\r\nall_areas_df %>%\r\n  ggplot(aes(mth, cases)) +\r\n  geom_col(aes(fill = yr)) +\r\n  # Facet data to show years and months\r\n  facet_wrap(~ yr) +\r\n  # Apply labels to numeric values\r\n  scale_x_continuous(breaks = 1:12,\r\n                     labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \r\n                                \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"),\r\n                     expand = c(0.01,0))\r\n\r\n\r\n\r\n\r\n\r\nFigure 2: A simple faceted column plot\r\n\r\n\r\n\r\nOur initial analysis of the main peak of cases at the end of 2012 and the start of 2022 was correct, but we can still do better.\r\nChanging the layout and palette\r\nThe standard ggplot2 colour scheme could definitely be better, so lets make a new palette of colours using the colorspace package.\r\n\r\n\r\n# Create colour palette using the burgyl (Burgundy-Yellow) palette\r\npal <- colorspace::sequential_hcl(length(unique(all_areas_df$yr)), palette = \"burgyl\")\r\n\r\n\r\nOur new layout will plot all the years horizontally across the plot, with a different colour for each year from the pal palette created above.\r\n\r\n\r\nall_areas_df %>%\r\n  ggplot(aes(mth, cases)) +\r\n  geom_col(aes(fill = yr)) +\r\n  # Facet data to show years and months\r\n  facet_wrap(~ yr) +\r\n  # Apply labels to numeric values\r\n  scale_x_continuous(breaks = 1:12,\r\n                     labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \r\n                                \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"),\r\n                     expand = c(0.01,0)) +\r\n  # Facet data to show years and months\r\n  facet_wrap(~ yr, nrow = 1, strip.position = \"bottom\") +\r\n  # Apply colour palette to columns\r\n  scale_fill_manual(\r\n    breaks = unique(all_areas_df$yr),\r\n    values = pal\r\n  ) +\r\n  # Expand y axis and format labels\r\n  scale_y_continuous(labels = label_comma(scale = 1e-6, accuracy = .2, suffix = \" m\"),\r\n                     expand = expansion(mult = c(0,.1)))\r\n\r\n\r\n\r\n\r\n\r\nFigure 3: A horizontal facet column plot\r\n\r\n\r\n\r\nAdding labels\r\nWe can now add some labels with some descriptive text explaining the chart to the viewer.\r\n\r\n\r\n# Title\r\ntitle_text <- \"How many Covid-19 cases submitted each month?\"\r\n\r\n# Extract items for use in subtitle\r\n# Sum of all cases\r\nall_cases <- sum(all_areas_df$cases)\r\n\r\n# The year with the max number of cases\r\nyr_max <- with(all_areas_df, yr[which.max(cases)])\r\n\r\n# The month name with the max number of cases\r\nmth_max <- month.name[with(all_areas_df, mth[which.max(cases)])]\r\n\r\n# The actual max number of cases for month\r\nmth_cases_max <- with(all_areas_df, cases[which.max(cases)])\r\n\r\n# Calculate the percent\r\nmth_cases_pct <- percent(mth_cases_max / all_cases, accuracy = .2)\r\n\r\n# Create Subtitle\r\nsubtitle_text <-\r\n  paste(\r\n    mth_max,\r\n    yr_max,\r\n    \"has the highest number of Covid-19 cases in England and Wales, \r\n    with a total of\",\r\n    comma(mth_cases_max),\r\n    \"cases. This represents\",\r\n    mth_cases_pct,\r\n    \"of the\",\r\n    comma(all_cases),\r\n    \"cases submitted for the complete period.\"\r\n  )\r\n\r\n# Create Caption\r\ncaption_text <-\r\n  \"Source: UK Health Security Agency at https://coronavirus.data.gov.uk/\"\r\n\r\n\r\nCreate the final plot\r\nNow we have our labels, let’s create the final plot, along with some amendments to the legend and theme.\r\n\r\n\r\nall_areas_df %>%\r\n  ggplot(aes(mth, cases)) +\r\n  geom_col(aes(fill = yr)) +\r\n  # Add labels\r\n  labs(\r\n    title = title_text,\r\n    subtitle = subtitle_text,\r\n    caption = caption_text) +\r\n  # Facet data to show years and months\r\n  facet_wrap(~ yr, nrow = 1) +\r\n  # Apply colour palette to columns\r\n  scale_fill_manual(\r\n    breaks = unique(all_areas_df$yr),\r\n    values = pal,\r\n    guide = guide_legend(\r\n      title = \"Year\", title.position = \"top\",\r\n      title.theme = element_text(size = 10, \r\n                                 family = \"roboto-condensed\", \r\n                                 face = \"bold\"),\r\n      label.position = \"bottom\"\r\n    )\r\n  ) +\r\n  # Apply labels to numeric values\r\n  scale_x_continuous(breaks = 1:12,\r\n  labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \r\n             \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"),\r\n  expand = c(0.01,0)) +\r\n  # Expand y axis and format labels\r\n  scale_y_continuous(labels = label_comma(scale = 1e-6, \r\n                                          accuracy = .2, \r\n                                          suffix = \" m\"),\r\n                     expand = expansion(mult = c(0,.1))) +\r\n  # Amend theme for plot elements\r\n  theme(\r\n    # Axis elements\r\n    axis.line.x = element_line(colour = \"grey70\"),\r\n    axis.text.x = element_text(colour = \"grey60\"),\r\n    axis.title = element_blank(),\r\n    # Panel elements\r\n    panel.grid.major.y = element_line(colour = \"grey70\", \r\n                                      linewidth = .2, \r\n                                      linetype = \"dashed\"),\r\n    panel.spacing = unit(0,'lines'),\r\n    # Remove Facet strip\r\n    strip.text = element_blank(),\r\n    # Legend formatting\r\n    legend.position = \"bottom\",\r\n    legend.direction = \"horizontal\",\r\n    legend.justification = \"left\",\r\n    legend.key.height = unit(.6, \"lines\"),\r\n    legend.key.width = unit(2, \"lines\"),\r\n    legend.spacing.x = unit(1, \"lines\")\r\n  )\r\n\r\n\r\n\r\n\r\n\r\nFigure 4: The final plot\r\n\r\n\r\n\r\nConclusion\r\nIn the next part, we shall zoom in on the data just for 2023 and a closer look at the data for the area of the UK where I live - North East England.\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-03-02-covid-visualisationpart-one/./all_areas_line_chart.png",
    "last_modified": "2023-03-14T17:40:10+00:00",
    "input_file": "covid-visualisationpart-one.knit.md"
  },
  {
    "path": "posts/2023-01-04-non-pivotpivots-part-three/",
    "title": "Making non-pivot tables summaries - Part 3",
    "description": "Sometimes people will mess up your pivot tables. Sometimes people will be terrified of pivot tables. In this third part of this series on non-pivot pivot tables, we look at the two new functions - HSTACK and VSTACK - combine them both with LET and we have true one cell reports.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2023-01-04",
    "categories": [
      "Excel",
      "Pivot Tables",
      "CHOOSE",
      "UNIQUE",
      "SORT",
      "SORTBY",
      "LET",
      "SEQUENCE",
      "INDEX",
      "HSTACK",
      "VSTACK",
      "Spilled Arrays",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nThe HSTACK function\r\nThe VSTACK function\r\nThe Source Data\r\nHow to arrange the data\r\nBuild initial LET function\r\nFirst Row\r\nSecond Row\r\nThird Row\r\nPutting it all together\r\n\r\nConclusion\r\n\r\nThe Problem\r\nIn the second part of this series, we saw how to create a one cell report using the LET function and a combination of SEQUENCE and SORTBY to create a summary table showing the totals of data by department.\r\nIn this part we will expand on the process to create a summary of data by Company and Department in a true one cell report.\r\nThe Solution\r\nSpilled arrays in MS Excel give us new powers in summarising data that allow us to do many new and wonderful things with data. Two new(ish) functions now available to users of MS365 are the HSTACK and VSTACK functions.\r\nUsing these two functions in combination with LET will allow detailed crosstab summary reports to be developed.\r\nThe HSTACK function\r\nThe H in HSTACK stands for Horizontal. The function allows for multiple arrays to be stacked horizontally across a range of cells. In the previous post, we saw how to use the CHOOSE function to spill data cross columns.\r\nThe MS Excel Help page for the HSTACK function states\r\n\r\nHSTACK returns the array formed by appending each of the array arguments in a column-wise fashion. The resulting array will be the following dimensions:\r\n- Rows The maximum of the row count from each of the array arguments.\r\n- Columns The combined count of all the columns from each of the array arguments.\r\n\r\nA simple example of HSTACK would be a joining three separate ranges into one.\r\n\r\n\r\n\r\nFigure 1: A simple HSTACK example\r\n\r\n\r\n\r\nThe formula shown in cell G3 shows that the three ranges in columns A, C and E have been stacked together across the columns G to I.\r\n\r\nThe ranges used in the HSTACK function do not need to be on the same worksheet in the workbook.\r\n\r\nThe VSTACK function\r\nThe V in VSTACK stands for Vertical. The function allows for multiple arrays to be stacked on top of each other across a range of rows. In the previous post, we saw how to use the a combination of the SEQUENCE, ROWS and SORTBY functions to sort a group of rows into the required order. The VSTACK function removes the need for those functions to be used.\r\nThe MS Excel Help page for the VSTACK function states\r\n\r\nVSTACK returns the array formed by appending each of the array arguments in a row-wise fashion. The resulting array will be the following dimensions:\r\n- Rows the combined count of all the rows from each of the array arguments.\r\n- Columns The maximum of the column count from each of the array arguments.\r\n\r\nA simple example of VSTACK would be a joining three separate ranges into one.\r\n\r\n\r\n\r\nFigure 2: A simple VSTACK formula\r\n\r\n\r\n\r\nThe Source Data\r\nThe source data we will be using for the examples is shown below. A simple table of just 10 rows of data showing orders made by certain departments in a company, the name of the supplier, the order and ship date along with the amount of the order.\r\n\r\n\r\n\r\nFigure 3: Source data\r\n\r\n\r\n\r\nHow to arrange the data\r\nBefore we start to build out our LET formula, we need to think about how the data will need to be arranged using the HSTACK and VSTACK functions inside the LET formula.\r\nThe image below gives an idea of what needs to be in each area of a summary table.\r\n\r\n\r\n\r\nFigure 4: Data arrangment\r\n\r\n\r\n\r\nIn this example, the three row groups will be created using the HSTACK function and will then be used within a VSTACK function to create the final summary table.\r\nBuild initial LET function\r\nBefore we start to use the two stacking functions, let’s build out our initial LET function with the required variables and columns of data.\r\nThe three columns from the source data table that will be used are the Company, Department and the Amount columns. As shown in part two, the LET function allows fro variables to be created and data ranges assigned to them. Using these columns and the LET function, our initial formula is shown below.\r\n\r\n\r\n\r\nFigure 5: The initial LET formula\r\n\r\n\r\n\r\nFirst Row\r\nFor our summary table, we need to have the names of the Department column from our source data, along with a title for the summary and a Grand Total column at the right hand side.\r\nCreating this formula outside of the LET function would be\r\n=HSTACK(\"Summary\", TRANSPOSE(SORT(UNIQUE(Data[Dept]))), \"Grand Total\")\r\nSecond Row\r\nThe second row will contain the main chunk of the data, listing the Company names, the total amounts for each Company and Department combination and a grand total row for each Company.\r\n=HSTACK(LeftColUniq, SUMIFS(ValuesCol, LeftCol, LeftColUniq, TopRow, TopRowUniq), SUMIFS(ValuesCol, LeftCol, LeftColUniq))\r\nThird Row\r\nThe final row will contain the grand total row for each Department, along with the overall total for all rows.\r\n=HSTACK(\"Grand Total\", SUMIFS(ValuesCol, TopRow, TopRowUniq), SUM(ValuesCol))\r\nPutting it all together\r\nUsing the VSTACK function, and placing the HSTACK formulas, along with out initial variables, the final table is created.\r\n\r\n\r\n\r\nFigure 6: The final formula\r\n\r\n\r\n\r\nConclusion\r\nUsing a combination of the LET, VSTACK and HSTACK formulas, a flexible method of summarising data can be reduced to one formula in one cell. With the added benefit of the summary will automatically refresh when new data is added, the need for pivot tables and people (managers) messing with the layout is removed.\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-01-04-non-pivotpivots-part-three/hstack.jpg",
    "last_modified": "2023-02-14T08:32:05+00:00",
    "input_file": "non-pivotpivots-part-three.knit.md"
  },
  {
    "path": "posts/2022-12-14-power-query-comments/",
    "title": "Using comments in Power Query",
    "description": "Comments are essential when developing power query items. They help to remind users what is happening and also for you develop the initial query.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-12-14",
    "categories": [
      "Excel",
      "Power Query",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nPower Query Comments\r\nSingle Line Comments\r\nMulti-line Comments\r\n\r\nKeyboard Shortcuts\r\nThe Final Query\r\n\r\nPower Query Comments\r\nWhen writing new Power Query items, it is good practice that comments are entered in the Advanced Editor window, to not only help you when you look back at a query weeks or months in the future, but also for others viewing the query.\r\nDepending on the complexity of the query, either one line or multi-line comments should be added, along with a header comment giving a basic overview of what the query actually does with data.\r\nSingle Line Comments\r\nA comment that is only on one line, maybe a quick explanation of what a particulat step performs, should be prefaced with two forward slashes, //, as below.\r\nlet\r\n    // Import data from Wiki page at the URL shown\r\n    Source = Web.Page(Web.Contents(\"https://en.wikipedia.org/wiki/List_of_London_Underground_stations\")){0}[Data]\r\nin\r\n    Source\r\nMulti-line Comments\r\nTo enter a multi-line comment, such as an overview of the steps taken by the query, comments should start with a /* and end with a */, as shown below. Adding a list of steps to the header comment at the initial creation of the data also acts as a reminder of the transformations that are needed to be completed to obtain the final result.\r\n/* \r\nQuery imports a complete list of London Underground Stations from the Wikipedia URL shown in the first step\r\n\r\n1. Imports data from URL\r\n2. Selects required columns\r\n3. Split Zones where station is in two zones\r\n4. Sets data types\r\n5. Rename columns\r\n */\r\n\r\nlet\r\n    // Import data from Wiki page at the URL shown\r\n    Source = Web.Page(Web.Contents(\"https://en.wikipedia.org/wiki/List_of_London_Underground_stations\")){0}[Data]\r\nin\r\n    Source\r\nKeyboard Shortcuts\r\nTo add the relevant comment indicators using keyboard shortcuts, the key combinations below should be used.\r\nCTRL + // to add or remove a single line comment\r\n\r\nALT + SHIFT + A to add or remove a multi-line comment\r\nThe Final Query\r\nThe full query with comments.\r\n/* \r\nQuery imports a complete list of London Underground Stations from the Wikipedia URL shown in the first step\r\n\r\n1. Import data from URL\r\n2. Select required columns\r\n3. Split Zones where station is in two zones\r\n4. Sets data types\r\n5. Rename columns\r\n\r\n */\r\n\r\nlet\r\n    // Import data from Wiki page at the URL shown\r\n    Source = Web.Page(Web.Contents(\"https://en.wikipedia.org/wiki/List_of_London_Underground_stations\")){0}[Data],\r\n\r\n    // First row as headers\r\n    MakeHeaders = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),\r\n\r\n    // Select the required columns\r\n    SelectColumns = Table.SelectColumns(MakeHeaders,\r\n        {\"Station\", \"Line(s)\", \"Zone(s)\", \"Usage\"}\r\n    ),\r\n\r\n    // Split Zone column by the & delimiter to new rows where a station is in two fare zones\r\n    SplitByDelimiter = Table.ExpandListColumn(\r\n        Table.TransformColumns(SelectColumns, \r\n            {\r\n                {\"Zone(s)\", Splitter.SplitTextByDelimiter(\" & \", QuoteStyle.Csv), \r\n                let itemType = (type nullable text) meta [Serialized.Text = true] in type {itemType}}\r\n            }\r\n            ), \r\n        \"Zone(s)\"\r\n    ),\r\n\r\n    // Set Data types\r\n    SetZoneDataType = Table.TransformColumnTypes(SplitByDelimiter,\r\n        {\r\n            {\"Zone(s)\", Int64.Type}, \r\n            {\"Usage\", type number}, \r\n            {\"Station\", type text}, \r\n            {\"Line(s)\", type text}\r\n        }\r\n    ),\r\n\r\n    // Rename columns i.e. remove (s) from column headers\r\n    RenameColumns = Table.RenameColumns(SetZoneDataType,\r\n        {\r\n            {\"Line(s)\", \"Lines\"}, {\"Zone(s)\", \"Zones\"}\r\n        }\r\n    )\r\nin\r\n    RenameColumns\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-03-03T14:28:15+00:00",
    "input_file": "power-query-comments.knit.md"
  },
  {
    "path": "posts/2022-11-23-non-pivotpivots-part-two/",
    "title": "Making non-pivot tables summaries - Part 2",
    "description": "Sometimes people will mess up your pivot tables. Sometimes people will be terrified of pivot tables. In this second part of this series on non-pivot pivot tables, we look at the LET function to create one cell reports",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-11-23",
    "categories": [
      "Excel",
      "Pivot Tables",
      "CHOOSE",
      "UNIQUE",
      "SORT",
      "SORTBY",
      "LET",
      "SEQUENCE",
      "INDEX",
      "Spilled Arrays",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nThe LET Formula\r\nA Simple Example\r\n\r\nThe Source Data\r\nSummary Table LET formula\r\nThe Vals variable\r\nThe Depts variable\r\nThe UniqDepts variable\r\nPutting it all together\r\n\r\nAdding a Total Row\r\nA Staging worksheet for calculations\r\nAdding a Grand Total Row\r\nThe SUM INDEX formula\r\nCreating row indices\r\nSorting the table rows\r\n\r\nAdding another summary column\r\nCHOOSE and SEQUENCE?\r\n\r\nConclusion\r\n\r\nThe Problem\r\nIn the first part of this series, we saw how to create a one cell report using a combination of formulas to show a summary of a table of data.\r\nIn this part we will expand on the process to create a summary of data and learn a few new tricks that will allow to expand our summary table and add a total row to the table.\r\nThe Solution\r\nAs mentioned in the first part, With the recent addition of spilled arrays in MS Excel, creating summaries of data can be completed using just one formula.\r\nBy using the LET and SEQUENCE formulas, we can enhance the one cell formula to prevent the repetition of certain formulas.\r\nThe LET Formula\r\nThe MS Excel Help page for the LET formula states\r\n\r\nThe LET function assigns names to calculation results. This allows storing intermediate calculations, values, or defining names inside a formula. These names only apply within the scope of the LET function. Similar to variables in programming, LET is accomplished through Excel’s native formula syntax. To use the LET function in Excel, you define pairs of names and associated values, and a calculation that uses them all. You must define at least one name/value pair (a variable), and LET supports up to 126.\r\n\r\nA Simple Example\r\nA simple example of a LET formula would be a simple multiplication of two values to obtain a result.\r\nA Simple LET formulaThe formula shown in cell A1 is a simple multiplication where the variable named a is assigned the value 10 and the variable b assigned the value 20. The last part of the LET formula is a multiplication of a*b to produce the result shown in the cell - 200\r\n\r\nThe variable names can be any value, but I would suggest not using any of the names used by Excel formulas and keeping the names short.\r\n\r\nThe variables listed in the formula can refer to cells, table columns, or named ranges.\r\nA simple LET formula with rangesAs explained in the standard Excel help, a set of variables and their associated value, values or calculations are created first. The last part of the LET formula is any final calculation that is required to provide the desired result.\r\nThe Source Data\r\nThe source data we will be using for the examples is shown below. A simple table of just 15 rows of data showing orders made by certain departments in a company, the name of the supplier, the order and ship date along with the amount of the order.\r\nSource DataThe data is saved in an MS Excel table with the name of Data on its own worksheet. We shall be adding a summary of the data by department showing how much each one spent on orders. Over the next several posts we shall expand on what the summary shows and the possible solutions.\r\nSummary Table LET formula\r\nBefore creating our LET formula, let’s review what we need to evaluate to create our final table of results\r\nThe values we need to summarise - the Amount column in the Data table\r\nThe column of data to summarise by - the Dept column in the Data table\r\nThe unique values of the column of data from item 2 above\r\nThe variable names we shall use should be simple and easily understood\r\nVals\r\nDepts\r\nUniqDepts\r\nBefore we build out full LET formula, lets build each one in turn and check what results we get when we use the variable name as the last parameter of the formula\r\nThe Vals variable\r\nAs mentioned above, the Vals variable will contain all the values we need to sum to produce our summary, the Amount column\r\nThe Vals variableThe Depts variable\r\nThe Depts variable will be the Department table column containing the values for each row\r\nThe Depts variableThe UniqDepts variable\r\nAs mentioned above, the use of the LET formula allows us to reuse values from one variable in another. For the list of unique Dept values, we can refer to the Depts variable created in the previous section.\r\nThe UniqDepts variablePutting it all together\r\nTo obtain our sum of values to show in our summary, we can use the variable names in the SUMIF formula and combine it with the CHOOSE formula to create our final table of data, as shown in the first part of this series.\r\nThe Final LET formula\r\nAdd line breaks in the formula by pressing ALT + RETURN\r\n\r\nAdding a Total Row\r\nTo add a total row, we have to resort to some witchcraft and trickery to fool Excel into presenting our final summary.\r\n\r\nNote - Some Excel users may have the HSTACK and VSTACK formulas available. This method will show how to add totals for those who have not yet had these two formulas made available to them. The method to use the HSTACK and VSTACK in the next part of this series.\r\n\r\nA Staging worksheet for calculations\r\nFor this example we will be using a separate worksheet to stage our formulas before the final presentation of the summary table. The Staging worksheet will contain all the required formulas and helper formulas to ensure our final table is in the correct layout.\r\nAdding a Grand Total Row\r\nTo calculate the total of the Total Amount column from our example above, we have several methods to obtain the value.\r\nJust use a SUM formula referencing the Amount column in the source data table\r\nUse a combination of SUM and INDEX to reference the LET formula created to show the main summary of data\r\nWe shall use the second version to obtain our final total amount value. The formula for the total row must be above the main LET formula and column headings. We shall use a trick in a following section to fool Excel into sorting the rows into the correct order\r\nThe Staging WorksheetThe SUM INDEX formula\r\nThe formula in cell B2 uses the INDEX formula to refer to the second column of the spilled array in cell A3.\r\n\r\nNote - The # after A3 tell Excel that the formula in the cell is a spilled array.\r\n\r\nThe INDEX formula has three parameters, array, row, column. In our example, we are referring to the spilled array in cell A3 and the second column. With the formula wrapped in a SUM formula, we obtain our final grand total value.\r\nCreating row indices\r\nTo sort the rows into the required order, we need to add some further formulas to ensure the rows are sorted correctly.\r\nBy using the SEQUENCE formula, we can create a further spilled array to identify the row numbers and use those values to sort the data.\r\nAdding row indicesThe formula in cell C8 uses the ROWS formula to count the number of rows in the spilled range in cell A3, adding one to ensure the total row is at the bottom once sorted\r\nThe column header rows have an index of 0 to ensure the headers are at the top once sorted\r\nThe individual rows within the main table, have indices based on the position in the table. Using the SEQUENCE formula and the ROWS formula we can create a spilled range of values in column C.\r\n\r\nNote - the formulas to identify the row index must be in the right hand column with no blank columns between\r\n\r\nSorting the table rows\r\nOnce we have the row index numbers created, we can now sort our table summary into the required order using the SORTBY formula.\r\nThis formula will sort one range of data by another range of data. In this case we want to sort the data in the range A1:B9 by the values in the cells C1:C9\r\n\r\n\r\n\r\nFigure 1: The SORTBY formula\r\n\r\n\r\n\r\nThe formula in cell E1 on the left hand window, has the SORTBY formula using the ranges mentioned above. The formula in cell A1 on the right hand window refers to the cell E1 on the staging worksheet with some additional formatting.\r\nThe issue with this method is that if a new department were to be added to the main source data table, the summary table would spill (expand) downwards, but the SORTBY formula would still have a hard-coded range.\r\nTricking SORTBY\r\nThe trick to ensure any expanded spilled range is include in a SORTBY formula is to use a little known trick when using spilled array formulas.\r\nUsually when selecting a range of cells from the bottom and dragging the mouse cursor upwards, Excel converts the range in a formula to read from the top row to the bottom row. When using spilled arrays, a three part range can be created.\r\n\r\n\r\n\r\nFigure 2: The final SORTBY formula\r\n\r\n\r\n\r\nThe formula in cell E1 refers to the dynamic range first, then the range of cells for the total row. The SORTBY formula then refers to the row index numbers by referring to the spilled SEQUENCE formula first.\r\nThe row for the column headers are automatically included.\r\nAdding another summary column\r\nTo add another column, say a count of the number of items for each department, just amend the array in the CHOOSE formula in the LET and add the extra calculation.\r\nAdd new column to SummaryCHOOSE and SEQUENCE?\r\nWhile the examples shown in the post use the CHOOSE formula to spill columns of data across a range, the SEQUENCE formula can also be used rather than a hard-coded array in the first parameter\r\nUsing SEQUENCE\r\nNote - the first parameter of the SEQUENCE formula has been omitted as this refers to rows and the second columns parameter used instead\r\n\r\nConclusion\r\nThis method takes some time to get used to, but once it is understood, creating summary tables that will automatically refresh with new data will come naturally.\r\nIn the next part of the series, we will look at how to create this summary of data but using the HSTACK and VSTACK formulas.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-23-non-pivotpivots-part-two/./pivot-table-summary.jpg",
    "last_modified": "2022-11-23T19:11:37+00:00",
    "input_file": "non-pivotpivots-part-two.knit.md"
  },
  {
    "path": "posts/2022-11-17-management-speak/",
    "title": "What do these even mean?",
    "description": "A project manager from a few years ago was very fond of management speak. Here are some of his classics",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-11-17",
    "categories": [
      "Fun",
      "Management Speak"
    ],
    "contents": "\r\nManagement Speak\r\nIn my previous post, I mentioned some project managers I had worked with over the past 25 years. This brought to mind a project manager, who I briefly worked with, and was determined to add as many phrases into his meetings as possible.\r\nGoogle defines Management Speak as\r\n\r\nlanguage regarded as characteristic of that used by managers in business, especially in being needlessly complex or filled with jargon.\r\n\r\nAnd with daily meetings, there were a lot. Here are the phrases I can remember or have made a note of.\r\nYou can’t rearrange the deckchairs on a sinking ship\r\nLet me paint a pen picture of our labour pyramid\r\nLet’s not be a crocodile lurking in the weeds\r\nLet’s take the topside on the argument before we chuck the sauce to it\r\nAt the moment we are just treading water around the common bazaars without the ability to gain the correct traction\r\nLet’s start getting to the mindset of not standing on shifting sands\r\nWe need to make sure our Knowledge Silos are able to withstand an attack\r\nWhat’s the assumption on the fleshing out task?\r\nStand up with our faces in the wind\r\nLet me point you towards the correct pictures so we can all have a group hug and have a proper drive at this\r\nLet’s focus on the future horizon and makes sure it is never cloudy\r\nAnd the all time classic, that was not actually said by this particular project manager, but was used in a teleconference and said by a team member working in the US.\r\nLet’s put that in the Thought Fridge and see who opens the door to munch on it\r\nPlease, stop. Just stop.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-17-management-speak/./speech.jpg",
    "last_modified": "2022-11-17T16:44:36+00:00",
    "input_file": "management-speak.knit.md"
  },
  {
    "path": "posts/2022-11-15-non-pivotpivots/",
    "title": "Making non-pivot tables summaries - Part 1",
    "description": "Sometimes people will mess up your pivot tables. Sometimes people will be terrified of pivot tables.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-11-15",
    "categories": [
      "Excel",
      "Pivot Tables",
      "CHOOSE",
      "UNIQUE",
      "SORT",
      "Spilled Arrays",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nThe Source Data\r\nSummary using a normal pivot table\r\nUsing CHOOSE and UNIQUE\r\nCHOOSE\r\nUNIQUE\r\n\r\nPutting it all together\r\nCreating our two formulas\r\nSorting the summary\r\n\r\n\r\nConclusion\r\n\r\nThe Problem\r\nI have worked with many project managers over the last 25 years. Many of them were very good at using MS Excel, some though were not. Two project managers spring to mind though. One was terrified of pivot tables. They insisted on not using them and would create workbooks with a sea of COUNTIFS and SUMIFS formulas. The other project manager loved pivot tables. Could not get enough of them. They would create pivot tables with practically every column available in a dataset, creating pivot tables that, if printed, could waste several trees of paper they were so large.\r\nThe Solution\r\nWith the recent addition of spilled arrays in MS Excel, creating summaries of data can be completed using just one formula. The advantage of using spilled arrays for summaries of data is that they updated automatically when new data is added to the source data unlike pivot tables, or summaries calculated through Power Query, that need to be refreshed via the Ribbon.\r\nThe Source Data\r\nThe source data we will be using for this example is shown below. A simple table of just 15 rows of data showing orders made by certain departments in a company, the name of the supplier, the order and ship date along with the amount of the order.\r\nSource DataThe data is saved in an MS Excel table with the name of Data on its own worksheet. We shall be adding a summary of the data by department showing how much each one spent on orders. Over the next several posts we shall expand on what the summary shows and the possible solutions.\r\nSummary using a normal pivot table\r\nUsing a normal pivot table for the source data, we are shown the summary below. We shall be recreating this summary using one formula.\r\nPivot Table SummaryUsing CHOOSE and UNIQUE\r\nA simple one cell summary formula can be created using the CHOOSE and UNIQUE formulas. But first lets look at the CHOOSE function in a little more details.\r\nCHOOSE\r\nThe MS Excel help for CHOOSE states:\r\n\r\nUses index_num to return a value from the list of value arguments. Use CHOOSE to select one of up to 254 values based on the index number. For example, if value1 through value7 are the days of the week, CHOOSE returns one of the days when a number between 1 and 7 is used as index_num.\r\n\r\nUsing the above description, we can create a formula that will identify the day of the week based on an input number.\r\nCHOOSE formulaThe CHOOSE function can also spilled values across columns. By using curly braces with a list of numbers in the first argument of the CHOOSE formula, we can add values across multiple columns in a row.\r\nCHOOSE formula spilling across many columnsAs shown in the image above, the three cells containing values in columns C, D and E have a blue border around. This indicates a spilled array.\r\nUNIQUE\r\nOne of the more powerful formulas to be added to MS Excel in recent years is the UNIQUE formula. As the name suggests, the formula will extract a list of unique values from a range of cells.\r\nUNIQUE formulaPutting it all together\r\nLooking at the standard pivot table solution shown above, we need to decide what we need to include in our summary of data.\r\nA list of unique department names from our source data table\r\nA SUMIF formula to calculate the total amount for each department\r\nCreating our two formulas\r\nFor our list of department names, we can use the formulas\r\n=UNIQUE(Data[Dept]) for the first column\r\n=SUMIF(Data[Dept], UNIQUE[Dept], Data[Amount]) for the second column\r\nUsing the CHOOSE formula that spills values across columns we can then create the formula below.\r\nSummary of DataWe get the same results, but with the department names in a different order.\r\nSorting the summary\r\nSorting the summary of data into the same order as the pivot table is as simple as wrapping our CHOOSE formula inside a SORT formula.\r\nSorted SummaryConclusion\r\nThis is a simple, but still powerful method to create a pivot table style summary using just formulas held in just one cell. This example could be expanded by amending the initial parameter in the CHOOSE function to show {1,2,3} and include a final column that shows the count of orders for each department.\r\nIn the next part, we will look at creating the same summary, but using two new formulas available in MS Excel - LET and SEQUENCE\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-15-non-pivotpivots/./pivot-table-summary.jpg",
    "last_modified": "2022-11-23T18:04:01+00:00",
    "input_file": "non-pivotpivots.knit.md"
  },
  {
    "path": "posts/2022-09-13-add-many-columns/",
    "title": "Adding Multiple Columns in Power Query",
    "description": "Adding multiple columns in Power Query can involve adding may steps. How about if it was possible to add many columns in one step?",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-09-13",
    "categories": [
      "Excel",
      "Power Query",
      "Tips & Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nThe Source Data\r\nAdding Records\r\nExpanding the Records\r\nUpdated M Code\r\n\r\nThe Problem with Records\r\nThe Solution\r\n\r\n\r\nConclusion\r\n\r\nThe Problem\r\nThere may be occasions when many columns are required to be added to a Power Query table. These new columns may be because of certain business rules, extracting information from an existing column or performing date and time calculations.\r\nThe Solution\r\nIn the post describing records we learnt that a power query can contain a record, or even a list of records, that contain multiple fields.\r\nRecords for each row in a table can be added via the normal Table.AddColumn function in Power Query. Many fields can be added to the record, with the required calculations, and then the record can be expanded to convert those record fields into new columns within the table.\r\nThe Source Data\r\nIn this example, we will be using a simple data set, stored in a table named Table1 on a worksheet within a workbook.\r\nSource Data in Table1The table is loaded in the usual manner into Power Query, via the From Table/Range button on the Data tab on the Excel Ribbon.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    )\r\nin\r\n    #\"Changed Type\"\r\n\r\nNote: This method does require manual typing of M Code in the Advanced Editor\r\n\r\nAdding Records\r\nTo add multiple columns, in this instance, we will add record fields for the year, month and month name from the Date column in the source table. As mentioned in the post describing records, records can be added by enclosing then in square brackets.\r\nOpen the Advanced Editor and add in the lines of M Code to create a new column containing a record for each row\r\n[\r\nName of Field = field value\r\n]\r\n\r\nUsing the Table.AddColumn function, we add the record for each row.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    ),\r\n    #\"Add Record\" = Table.AddColumn(#\"Changed Type\",\r\n        \"Record\",\r\n        each\r\n            [\r\n                Year = Date.Year([Date]),\r\n                Month = Date.Month([Date]),\r\n                Month Name = Date.MonthName([Date]),\r\n                Short Month Name = Text.Start(#\"Month Name\", 3)\r\n            ]\r\n    )\r\nin\r\n    #\"Add Record\"\r\n\r\nAs shown below, each row now has a Record in the new Record column.\r\nAdd RecordClicking in an empty area of a cell to the right of one of the Record items will show the field values in the record, as shown at the bottom of the image above.\r\nExpanding the Records\r\nNow each row has a record, the fields need to be expanded to create new columns in table. This is achieved by clicking the double arrows at the top of the Record column.\r\nExpand RecordClicking this double arrow button will show a pop-up with a list of the field available\r\nRecord Fields\r\nNote: It is suggested that the checkmark is removed for the Use original column name for prefix checkbox at the bottom of the pop-up\r\n\r\nOnce the OK button on the pop-up is clicked, the new columns will be added to the table.\r\nExpanded RecordUpdated M Code\r\nAfter the record column has been expanded, the extra M code, in the last #\"Expanded Record step has been added to the Power Query table.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    ),\r\n    #\"Add Record\" = Table.AddColumn(#\"Changed Type\",\r\n        \"Record\",\r\n        each\r\n            [\r\n                Year = Date.Year([Date]),\r\n                Month = Date.Month([Date]),\r\n                Month Name = Date.MonthName([Date]),\r\n                Short Month Name = Text.Start(#\"Month Name\", 3)\r\n            ]\r\n    ),\r\n    #\"Expanded Record\" = Table.ExpandRecordColumn(#\"Add Record\", \r\n        \"Record\", \r\n        {\"Year\", \"Month\", \"Month Name\", \"Short Month Name\"}, \r\n        {\"Year\", \"Month\", \"Month Name\", \"Short Month Name\"}\r\n    )\r\nin\r\n    #\"Expanded Record\"\r\n\r\n\r\nNote: The second list of field names in the #\"Expanded Record step is not actually required. The step will work fine without this. The second list is used if a new name is needed for the expanded record field.\r\n\r\nThe Problem with Records\r\nLooking at the column headers for the new columns, the icon shown is for the any data type icon of 123ABC. We would then need to set the correct data type for each of these new columns manually.\r\nColumn Data TypesThe Solution\r\nTo remove the need to manually set the data types for columns created from record fields, the initial M code that created the record can be amended. Adding another record within the step listing the data types solves this issue.\r\nlet\r\n    Source = Excel.CurrentWorkbook(){[Name=\"Table1\"]}[Content],\r\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,\r\n        {\r\n            {\"Index\", Int64.Type}, {\"Supplier\", type text}, \r\n            {\"Date\", type date}, {\"Amount\", type number}\r\n        }\r\n    ),\r\n    #\"Add Record\" = Table.AddColumn(#\"Changed Type\",\r\n        // Set the name of the new column\r\n        \"Record\",\r\n        \r\n        // Add fields to the recoed by wrapping in square brackets\r\n        each\r\n            [\r\n                Year = Date.Year([Date]),\r\n                Month = Date.Month([Date]),\r\n                Month Name = Date.MonthName([Date]),\r\n                \r\n                // Note that the Month Name field must be enclosed in a # and \"\" as the field is\r\n                // referenced in a standard function.\r\n                Short Month Name = Text.Start(#\"Month Name\", 3)\r\n            ],\r\n            \r\n            // Add a type record to assign data types to each field in the record\r\n            type\r\n            [\r\n                Year = Int64.Type,\r\n                Month = Int64.Type,\r\n                Month Name = text,\r\n                Short Month Name = text\r\n            ]\r\n    ),\r\n    #\"Expanded Record\" = Table.ExpandRecordColumn(#\"Add Record\", \r\n        // Name of the column to expand\r\n        \"Record\", \r\n        \r\n        // The fields to expand\r\n        {\"Year\", \"Month\", \"Month Name\", \"Short Month Name\"}\r\n    )\r\nin\r\n    #\"Expanded Record\"\r\n\r\n\r\nNote: The #“Expanded Record” step has had the second list of field names removed.\r\n\r\nOnce this new record listing the field data types have been added, the column data types now have the correct type assigned.\r\nColumn Data TypesConclusion\r\nThis method of adding multiple columns is quick, and once the structure is understood, a standard method for adding new columns, reducing the number of steps in a Power Query.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-09-13-add-many-columns/./source-data.jpg",
    "last_modified": "2022-09-13T18:22:12+01:00",
    "input_file": "add-many-columns.knit.md"
  },
  {
    "path": "posts/2022-08-31-presidential-campaigns/",
    "title": "Presidential Donations",
    "description": "How much were donations made to Presidential Campaigns?.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-30",
    "categories": [
      "R",
      "Tidy Tuesdays",
      "dplyr",
      "ggplot"
    ],
    "contents": "\r\n\r\nContents\r\nTidy Tuesday\r\nThe Data\r\nTidy the\r\ndata\r\nAdd\r\nvariables\r\nWhat’s in\r\nthe data?\r\n\r\nUS State\r\ndata\r\nCalculating the plot data\r\nJoining the\r\ndata\r\n\r\nBuilding the\r\nplot\r\nCreating plot labels\r\nMaking the final plot\r\nChange\r\nthose colours\r\nImproving the theme\r\n\r\nConclusion\r\n\r\nTidy Tuesday\r\nI decided to start posting items for the\r\nR for Data Science Tidy Tuesday project where data sets are\r\nreleased each Monday as part of the\r\nR4DS Online Learning Community. A quote from the home page\r\nstates -\r\n\r\nThe intent of Tidy Tuesday is to provide a safe and supportive forum\r\nfor individuals to practice their wrangling and data visualization\r\nskills independent of drawing conclusions. While we understand that the\r\ntwo are related, the focus of this practice is purely on building skills\r\nwith real-world data.\r\n\r\nThe Data\r\nI found the datasets used in this post by accident, while looking for\r\nanother item for a totally unrelated project, and thought this would be\r\na good starter for my first contribution.\r\nThe dataset is available here\r\nand is a zip file and the contents extracted to the data sub-folder.\r\n\r\nThe file is large, over 600Mb, so if you choose to use this data, be\r\nmindful of where you store the csv file.\r\n\r\n\r\n\r\n# Read data to a data frame\r\n\r\ndf <- read_csv(\"P00000001-ALL.csv\",\r\n               show_col_types = FALSE)\r\n\r\nstr(df)\r\n\r\nspec_tbl_df [4,084,074 × 16] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\r\n $ cmte_id          : chr [1:4084074] \"C00420224\" \"C00420224\" \"C00420224\" \"C00420224\" ...\r\n $ cand_id          : chr [1:4084074] \"P80002983\" \"P80002983\" \"P80002983\" \"P80002983\" ...\r\n $ cand_nm          : chr [1:4084074] \"Cox, John H\" \"Cox, John H\" \"Cox, John H\" \"Cox, John H\" ...\r\n $ contbr_nm        : chr [1:4084074] \"BROWN, CHARLENE\" \"KELLY, RAY\" \"CINGEL, KEITH\" \"DUNAWAY, JONATHON\" ...\r\n $ contbr_city      : chr [1:4084074] \"EAGLE RIVER\" \"HUNTSVILLE\" \"SEVERN\" \"DEATSVILLE\" ...\r\n $ contbr_st        : chr [1:4084074] \"AK\" \"AL\" \"AL\" \"AL\" ...\r\n $ contbr_zip       : chr [1:4084074] \"99577\" \"35801\" \"20999\" \"36022\" ...\r\n $ contbr_employer  : chr [1:4084074] NA \"ARKTECH\" \"SANTA CLAUS\" \"CSC\" ...\r\n $ contbr_occupation: chr [1:4084074] \"STUDENT\" \"RETIRED\" \"SNOWMAN\" \"TECHNICAL MANAGER\" ...\r\n $ contb_receipt_amt: num [1:4084074] 25 25 50 10 25 25 20 5 10 10 ...\r\n $ contb_receipt_dt : chr [1:4084074] \"01-MAR-07\" \"25-JAN-07\" \"17-MAY-07\" \"18-JAN-07\" ...\r\n $ receipt_desc     : chr [1:4084074] NA NA NA NA ...\r\n $ memo_cd          : chr [1:4084074] NA NA NA NA ...\r\n $ memo_text        : chr [1:4084074] NA NA NA NA ...\r\n $ form_tp          : chr [1:4084074] \"SA17A\" \"SA17A\" \"SA17A\" \"SA17A\" ...\r\n $ file_num         : num [1:4084074] 288757 288757 305408 288757 288757 ...\r\n - attr(*, \"spec\")=\r\n  .. cols(\r\n  ..   cmte_id = col_character(),\r\n  ..   cand_id = col_character(),\r\n  ..   cand_nm = col_character(),\r\n  ..   contbr_nm = col_character(),\r\n  ..   contbr_city = col_character(),\r\n  ..   contbr_st = col_character(),\r\n  ..   contbr_zip = col_character(),\r\n  ..   contbr_employer = col_character(),\r\n  ..   contbr_occupation = col_character(),\r\n  ..   contb_receipt_amt = col_double(),\r\n  ..   contb_receipt_dt = col_character(),\r\n  ..   receipt_desc = col_character(),\r\n  ..   memo_cd = col_character(),\r\n  ..   memo_text = col_character(),\r\n  ..   form_tp = col_character(),\r\n  ..   file_num = col_double()\r\n  .. )\r\n - attr(*, \"problems\")=<externalptr> \r\n\r\n16 variables are available in the data, but I will concentrate on the\r\ncontbr_st, contb_receipt_dt and\r\ncontb_receipt_amt variables to create a map showing which\r\nstates contributed the most dollars to campaigns. I’m not happy with\r\nthose variable names, so lets rename them.\r\nTidy the data\r\n\r\n\r\ndf <- df %>% \r\n  select(\r\n    city = contbr_city,\r\n    state_abb = contbr_st,\r\n    amount = contb_receipt_amt,\r\n    date = contb_receipt_dt\r\n  )\r\n\r\n\r\nAdd variables\r\nLet’s continue some basic tidying up of the data by ensuring the\r\ndate variable is recognised as a proper date values and add\r\na year variable.\r\n\r\n\r\ndf <- df %>% \r\n  mutate(date = dmy(date),\r\n         yr = as.numeric(year(date)))\r\n\r\n\r\nWhat’s in the data?\r\nWhat sort of spread of data do we have for each year in the data?\r\n\r\n\r\ndf %>% \r\n  group_by(yr) %>% \r\n  count(yr)\r\n\r\n# A tibble: 5 × 2\r\n# Groups:   yr [5]\r\n     yr       n\r\n  <dbl>   <int>\r\n1  2004       3\r\n2  2005     106\r\n3  2006    6089\r\n4  2007  691650\r\n5  2008 3386226\r\n\r\nIt looks like the first three years worth of the data contain low\r\nnumbers, so let’s exclude them from the data set - we may want to facet\r\nthe data later when we plot the map.\r\n\r\n\r\ndf <- df %>% \r\n  filter(date >= as.Date(\"2007-01-01\"))\r\n\r\n\r\nUS State data\r\nI had been aware of the built-in data sets within R and the various\r\nlibraries, but had never used them in a project. Let’s change that and\r\nget some data relating to the US States.\r\n\r\n\r\nstate_names <- data.frame(state_abb = state.abb,\r\n                          state_name = state.name)\r\n\r\nhead(state_names)\r\n\r\n  state_abb state_name\r\n1        AL    Alabama\r\n2        AK     Alaska\r\n3        AZ    Arizona\r\n4        AR   Arkansas\r\n5        CA California\r\n6        CO   Colorado\r\n\r\nLooking at the data_map(\"state\") data set that comes\r\nwith ggplot2, containing the longitude and latitude\r\nvariables for states, the region name is in lowercase, so let’s create\r\nthat data frame again, with a lower case state name\r\n\r\n\r\nstate_names <- data.frame(state_abb = state.abb,\r\n                          state_name = str_to_lower(state.name))\r\n\r\nhead(state_names)\r\n\r\n  state_abb state_name\r\n1        AL    alabama\r\n2        AK     alaska\r\n3        AZ    arizona\r\n4        AR   arkansas\r\n5        CA california\r\n6        CO   colorado\r\n\r\nCreate a new data frame containing the longitude and latitude\r\nvariables and join it to the state names\r\n\r\n\r\nmap_coords <- map_data(\"state\") %>% \r\n  inner_join(state_names, by = c(\"region\" = \"state_name\"))\r\n\r\nhead(map_coords)\r\n\r\n       long      lat group order  region subregion state_abb\r\n1 -87.46201 30.38968     1     1 alabama      <NA>        AL\r\n2 -87.48493 30.37249     1     2 alabama      <NA>        AL\r\n3 -87.52503 30.37249     1     3 alabama      <NA>        AL\r\n4 -87.53076 30.33239     1     4 alabama      <NA>        AL\r\n5 -87.57087 30.32665     1     5 alabama      <NA>        AL\r\n6 -87.58806 30.32665     1     6 alabama      <NA>        AL\r\n\r\nCalculating the plot data\r\nTo plot the data for amounts donated to the Presidential Campaigns,\r\nwe need the total amounts by state.\r\n\r\n\r\ndonations_by_state <- df %>% \r\n  group_by(state_abb, yr) %>% \r\n  summarise(total_amount = sum(amount), .groups = \"drop\")\r\n\r\nhead(donations_by_state)\r\n\r\n# A tibble: 6 × 3\r\n  state_abb    yr total_amount\r\n  <chr>     <dbl>        <dbl>\r\n1 -          2008          50 \r\n2 -1         2008        3100 \r\n3 0          2008       -4368.\r\n4 1          2008         376.\r\n5 60         2007         800 \r\n6 60         2008        1030 \r\n\r\nJoining the data\r\nWe can see from the donations_by_state data frame, we\r\nhave multiple rows with invalid state names.\r\n\r\n\r\nunique(donations_by_state$state_abb)\r\n\r\n  [1] \"-\"  \"-1\" \"0\"  \"1\"  \"60\" \"75\" \"AA\" \"AB\" \"AC\" \"AE\" \"AF\" \"AK\" \"AL\"\r\n [14] \"AM\" \"AN\" \"AP\" \"AR\" \"AS\" \"AU\" \"AZ\" \"BA\" \"BC\" \"BE\" \"BH\" \"BM\" \"BR\"\r\n [27] \"C\"  \"CA\" \"CH\" \"CN\" \"CO\" \"CT\" \"DC\" \"DE\" \"DF\" \"DI\" \"DJ\" \"EN\" \"ES\"\r\n [40] \"EU\" \"FF\" \"FI\" \"FL\" \"FM\" \"FR\" \"GA\" \"GE\" \"GH\" \"GR\" \"GU\" \"HE\" \"HI\"\r\n [53] \"HK\" \"HO\" \"HU\" \"IA\" \"ID\" \"IL\" \"IN\" \"IO\" \"IR\" \"IS\" \"IT\" \"JA\" \"JP\"\r\n [66] \"JT\" \"KE\" \"KS\" \"KT\" \"KY\" \"LA\" \"LN\" \"LO\" \"LU\" \"MA\" \"MB\" \"MD\" \"ME\"\r\n [79] \"MH\" \"MI\" \"ML\" \"MN\" \"MO\" \"MP\" \"MS\" \"MT\" \"MU\" \"MX\" \"MY\" \"N\"  \"N.\"\r\n [92] \"N/\" \"NC\" \"ND\" \"NE\" \"NH\" \"NJ\" \"NL\" \"NM\" \"NO\" \"NS\" \"NT\" \"NU\" \"NV\"\r\n[105] \"NY\" \"OC\" \"OH\" \"OK\" \"ON\" \"OR\" \"OT\" \"PA\" \"PE\" \"PO\" \"PR\" \"PW\" \"QB\"\r\n[118] \"QC\" \"QL\" \"QU\" \"RE\" \"RH\" \"RI\" \"RM\" \"SA\" \"SC\" \"SD\" \"SE\" \"SK\" \"SO\"\r\n[131] \"SP\" \"ST\" \"SU\" \"SW\" \"TA\" \"TE\" \"TH\" \"TK\" \"TN\" \"TO\" \"TP\" \"TR\" \"TU\"\r\n[144] \"TX\" \"TZ\" \"U.\" \"UK\" \"US\" \"UT\" \"VA\" \"VE\" \"VI\" \"VK\" \"VT\" \"WA\" \"WE\"\r\n[157] \"WI\" \"WV\" \"WY\" \"XX\" \"YT\" \"ZU\" \"ZZ\" NA  \r\n\r\nBy joining the data frame to the map_coords data frame,\r\nthese invalid rows will be removed.\r\n\r\n\r\nplot_data <- inner_join(x = map_coords, y = donations_by_state)\r\n\r\nhead(plot_data)\r\n\r\n       long      lat group order  region subregion state_abb   yr\r\n1 -87.46201 30.38968     1     1 alabama      <NA>        AL 2007\r\n2 -87.46201 30.38968     1     1 alabama      <NA>        AL 2008\r\n3 -87.48493 30.37249     1     2 alabama      <NA>        AL 2007\r\n4 -87.48493 30.37249     1     2 alabama      <NA>        AL 2008\r\n5 -87.52503 30.37249     1     3 alabama      <NA>        AL 2007\r\n6 -87.52503 30.37249     1     3 alabama      <NA>        AL 2008\r\n  total_amount\r\n1      2382083\r\n2      3661394\r\n3      2382083\r\n4      3661394\r\n5      2382083\r\n6      3661394\r\n\r\nBuilding the plot\r\nNow we have the data joined together, let’s make the first plot to\r\nsee what we have.\r\n\r\n\r\np <- ggplot(plot_data, aes(long, lat)) +\r\n  geom_polygon(aes(group = group, fill = total_amount),\r\n               colour = \"grey30\",\r\n               size = .2)\r\n\r\np\r\n\r\n\r\n\r\nI definitely do not like that standard blue for a continuous scale,\r\nwe will change that later on!\r\nWe can tell which are the top states making donations, but my being a\r\nBrit, I’m not always confident on which states are which (I know\r\nCalifornia, Texas and New York though!), so let’s find out the top 5\r\nstates making donations by looking at the\r\ndonations_by_state data frame again. We can use this later\r\nto create some descriptive text for the plot subtitle.\r\n\r\n\r\ntop_five_state_abb <- donations_by_state %>% \r\n  group_by(state_abb) %>% \r\n  summarise(total_amount = sum(total_amount)) %>% \r\n  arrange(desc(total_amount)) %>% \r\n  top_n(n = 5)\r\n\r\ntop_five_state_abb\r\n\r\n# A tibble: 5 × 2\r\n  state_abb total_amount\r\n  <chr>            <dbl>\r\n1 CA          177005057.\r\n2 NY          122472922.\r\n3 TX           65920709.\r\n4 FL           58941780.\r\n5 IL           54418090.\r\n\r\nCreating plot labels\r\nSo we can have a plot that explains what is being shown, we can\r\ncreate some text variables that will be used by the labs\r\nfunction when creating the plot.\r\n\r\n\r\nplot_title <- \"Which states donated the most for the US Presidential Campaigns?\"\r\n\r\nplot_caption <- \"Data Source: https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/pages/datasets-and-code/\"\r\n\r\n\r\nMaking a descriptive subtitle for the plot, we need to look back at\r\nsome of the earlier data frames and summarise the data a little\r\nfurther.\r\n\r\n\r\ntotal_donations <- inner_join(x = state_names, y = df) %>% \r\n  summarise(total_amount = sum(amount)) %>% pull(total_amount)\r\n\r\ntotal_donations\r\n\r\n[1] 995334194\r\n\r\nCreate the total amount donated by the top five states and calculate\r\nthe percentage of all donations.\r\n\r\n\r\ntop_five_amount <- sum(top_five_state_abb$total_amount)\r\n\r\ntop_five_pct <- percent(top_five_amount / total_donations, accuracy = .2)\r\n\r\ntop_five_amount <- dollar(top_five_amount, accuracy = .2, scale = 1e-6, suffix = \"m\")\r\n\r\ntotal_donations <- dollar(total_donations, accuracy = .2, scale = 1e-6, suffix = \"m\")\r\n\r\ntop_five_amount\r\n\r\n[1] \"$478.8m\"\r\n\r\ntop_five_pct\r\n\r\n[1] \"48.2%\"\r\n\r\ntotal_donations\r\n\r\n[1] \"$995.4m\"\r\n\r\nCreate a text string for the top five states donating.\r\n\r\n\r\ntop_five_states <- toString(top_five_state_abb %>% pull(state_abb))\r\n\r\n\r\nNow we have the amounts needed for the subtitle, lets make the text\r\nvariable, with a line break at the start to add some spacing.\r\n\r\n\r\nplot_subtitle <- glue::glue(\r\n  \"A total of {total_donations} was contributed from all states, with the top five states of {top_five_states}, contributing a total of {top_five_amount},<br />representing {top_five_pct} of all donations in 2007 & 2008\")\r\n\r\n\r\nMaking the final plot\r\n\r\n\r\np <- p +\r\n  labs(\r\n    title = plot_title,\r\n    subtitle = plot_subtitle,\r\n    caption = plot_caption,\r\n    fill = NULL # Remove legend title\r\n  )\r\n\r\np\r\n\r\n\r\n\r\nChange those colours\r\nAs I said previously, I do not like the standard blue colour that\r\ncomes with a continuous scale, let’s change and change the type of map\r\nprojection shown in the plot.\r\n\r\n\r\np <- p +\r\n  scale_fill_continuous(\r\n    low = '#FFF8DC',\r\n    high = '#8B1A1A',\r\n    labels = label_dollar(\r\n      scale = 1e-6,\r\n      suffix = \"m\",\r\n      accuracy = .2\r\n    )\r\n  ) +\r\n  coord_map(projection = \"mollweide\")\r\n\r\np\r\n\r\n\r\n\r\nImproving the theme\r\nLoad my preferred fonts for plot text and titles.\r\n\r\n\r\nfont_add_google(family = \"roboto-slab\", \"Roboto Slab\")\r\nfont_add_google(family = \"roboto-condensed\", \"Roboto Condensed\")\r\n\r\nshowtext_auto()\r\n\r\n\r\nVoid the theme by using theme_void\r\n\r\n\r\np <- p + theme_void()\r\n\r\np \r\n\r\n\r\n\r\nAs the amount of text for the title and subtitle overflow the plot\r\narea, we need to use the element_textbox_simple from the\r\nggtext package to allow for overflowing text and add all\r\nthe other plot theme elements.\r\n\r\n\r\np <- p +\r\n  theme(\r\n    text = element_text(family = \"roboto-condensed\", size = 22),\r\n    plot.margin = margin(rep(1, 4), unit = \"cm\"),\r\n    legend.direction = \"horizontal\",\r\n    legend.position = \"bottom\",\r\n    legend.key.height = unit(.8, units = \"lines\"),\r\n    legend.key.width = unit(3.5, units = \"lines\"),\r\n    legend.margin = margin(b = 1, unit = \"lines\"),\r\n    plot.title = element_text(\r\n      face = \"bold\",\r\n      size = 26,\r\n      family = \"roboto-slab\",\r\n      colour = \"#8B1A1A\"\r\n    ),\r\n    plot.title.position = \"plot\",\r\n    plot.subtitle = element_markdown(),\r\n    plot.caption = element_text(size = 14, hjust = 0, face = \"italic\"),\r\n    plot.caption.position = \"plot\",\r\n    panel.grid = element_line(\r\n      colour = \"grey30\",\r\n      size = .2,\r\n      linetype = \"dashed\"\r\n    )\r\n  )\r\n\r\np\r\n\r\n\r\n\r\nConclusion\r\nOverall, for a first attempt at using the maps data sets and plotting\r\ndata, I’m happy with the result.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-31-presidential-campaigns/./us_map.jpg",
    "last_modified": "2022-08-31T19:25:47+01:00",
    "input_file": "presidential-campaigns.knit.md"
  },
  {
    "path": "posts/2022-08-23-parameters-record/",
    "title": "Making parameters a record",
    "description": "Using a record to store your worksheet parameters.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-23",
    "categories": [
      "Excel",
      "Power Query",
      "Tips and Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nUsing\r\nRecords\r\nUsing a value from a record\r\nfield\r\nMultiple\r\nRecords\r\nUsing a value from a\r\nmulti-record list\r\nCreating the parameters\r\nrecord\r\n\r\nConclusion\r\n\r\nThe Problem\r\nIn the last\r\npost we learnt how to create Power Query parameters from named\r\nranges on a worksheet using just one line of M Code. This method is\r\ngreat if the set of queries only have a few parameters that would be\r\nreferences, but what if there were many parameters? There is the\r\npossibility that with a large number of parameters, keep track of them\r\nall in the Power Query Editor could cause issues. What if we could store\r\nthem all in one query?\r\nThe Solution\r\nUsing Records\r\nA record can be thought of as a single vertical column of data. Think\r\nof it as one row from a table of data, but shown vertically. Records in\r\nPower Query can be in tables, lists and can also be created manually if\r\nneeded.\r\nThe structure of a record requires a name for a field within the\r\nrecord and a value to store within that field. All fields that are\r\nwithin a record must be wrapped in square brackets.\r\n[\r\n    Name = \"Mickey Mouse\",\r\n    Role = \"Cartoon Mouse\",\r\n    Name of Spouse = \"Minnie Mouse\"\r\n]\r\nA single record\r\nNote - A field within a record can contain multiple spaces without\r\nthe need to wrap the name within a #“” in a normal power query. Values\r\nassigned to fields must have the value enclosed in quotes if spaces are\r\nin the value.\r\n\r\nUsing a value from a record\r\nfield\r\nTo refer to a field within a record, the name of the query and the\r\nfield name can be used using the syntax of\r\nQueryName[FieldName]\r\nFor the example above, if the query name was Mickey, to\r\nextract each of the values, the M code would be\r\nMickey[Name]\r\n\r\nMickey[Role]\r\n\r\nMickey[Name of Spouse]\r\nMultiple Records\r\nTo create multiple records within one query, wrap the records within\r\ncurly brackets. Using curly brackets converts this query to a list.\r\n\r\nNote: Each record must contain the same field names, although a field\r\ncan contain a null value.\r\n\r\n{\r\n    [\r\n        Name = \"Mickey Mouse\",\r\n        Role = \"Cartoon Mouse\",\r\n        Name of Spouse = \"Minnie Mouse\"\r\n    ],\r\n    [\r\n        Name = \"Donald Duck\",\r\n        Role = \"Cartoon Duck\",\r\n        Name of Spouse = \"Daisy Duck\"\r\n    ]\r\n}\r\nA list of recordsUsing a value from a\r\nmulti-record list\r\nAs Power Query uses zero-based counting, the first record in the\r\nexample above, would have a zero index, the second record would have an\r\nindex of 1, and so on. To extract a value from the multi-record list,\r\nuse the syntax QueryName{Index}[FieldName]\r\nFor the example above, if the query name was Characters,\r\nto extract each of the values for the name fields, the M code would\r\nbe\r\nCharacters{0}[Name]\r\n\r\nCharacters{1}[Name]\r\n\r\nExtracting name from first\r\nrecordCreating the parameters\r\nrecord\r\nUsing the methods above, we can create our record for storing the\r\nparameters by wrapping the three items in square brackets and create a\r\nmulti-field single record query named FileParameters\r\n[\r\n    DataPath = Excel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1] \r\n    meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false],\r\n    \r\n    MainSource = Excel.CurrentWorkbook(){[Name=\"Main_Source\"]}[Content]{0}[Column1] \r\n    meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false],\r\n    \r\n    Lookups = Excel.CurrentWorkbook(){[Name=\"Lookups\"]}[Content]{0}[Column1] \r\n    meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\n]\r\n\r\n\r\nNote: There is no need for an = sign at the start of a query\r\ncontaining a record.\r\n\r\nTo use the parameters above in a query to load data, we call the\r\nFileParameters query and use the relevant fields to extract\r\nthe required data.\r\nlet\r\n    Source = Csv.Document(\r\n        File.Contents(\r\n            FileParameters[DataPath] & FileParameters[MainSource]\r\n            ),\r\n        [Delimiter=\",\", Columns=4, Encoding=1252, QuoteStyle=QuoteStyle.None]\r\n    )\r\nin\r\n    Source\r\n\r\nConclusion\r\nUsing a parameters query to store values from named ranges on a\r\nworksheet may take a little effort to initially set-up, but I believe\r\nthat outweighs the need to remember how to refer to or look up the\r\nsyntax to extract a named range each time one is needed to be used.\r\nI have also seen vast improvements in the speed of loading data from\r\nworkbooks, either saved locally or on SharePoint sites, from several\r\nminutes to just a few seconds.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-23-parameters-record/./parameters-record-overview.jpg",
    "last_modified": "2022-08-23T16:13:25+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-15-how-to-parameterise/",
    "title": "How to parameterise",
    "description": "There are many ways to use parameters in Power Query. Here's my favourite method",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-15",
    "categories": [
      "Excel",
      "Power Query",
      "Tips and Tricks"
    ],
    "contents": "\r\n\r\nContents\r\nThe Problem\r\nThe Solution\r\nTL;DR\r\nCreating a Named Range\r\nExtracting the Named Range\r\nvalue\r\nCreate the Power Query\r\nParameter\r\nUsing\r\nthe Parameter\r\n\r\nConclusion\r\n\r\nThe Problem\r\nWhen I first started using Power Query, in one of its very early\r\nversions, file paths to data sources were often hard-coded into each\r\nquery. This would cause issues if the workbook was sent to another user\r\nand the data source was in a folder on my file structure, obviously, the\r\nother user would not have access to my folders!\r\nThe method of using filenames then changed to using a table on a\r\nworksheet, often named Parameters that would list all the\r\nfile paths for all data sources used by Power Query. This method worked\r\nfine until one monster of a workbook was developed. With 17 or so data\r\nsources from a variety of locations, both shared network folders and\r\nSharePoint Document Libraries, the process began to get slower and\r\nslower.\r\nTo extract a file path and name from the Parameters\r\nworksheet would take an age to load in the Power Query Editor window\r\njust to make a change to the query or to refresh it when in the editor\r\nwindow.\r\nA new method was needed.\r\nThe Solution\r\nI had used the New Parameter method from the Power Query\r\nEditor window to add a value to an item, but others using the workbook\r\nare not always confident in using the editor. The solution was to use\r\nExcel Named Ranges and call them in one line of M code.\r\nTL;DR\r\nCreate a new blank query\r\nRename the query to the required name\r\nOpen the Advanced Editor\r\nRemove the M code shown\r\nPaste in the line below, replacing the Data_Path value\r\nto the name of your named range\r\nExcel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1] meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\nClick OK\r\nCreating a Named Range\r\nA named range in Excel can be a single cell or any number of cells\r\nthat have a name assigned to them. Named ranges can be accessed from the\r\ndrop down box to the left of the formula bar.\r\nNamed Range Drop Down ListFor this example, I have created three named ranges, one for each\r\nfile and the data path those files are saved in.\r\nExanple FilesEach cell has been named based on the value in column B of the\r\nworksheet. Spaces have been replaced with underscores where they\r\nexist.\r\nTo create a named range quickly, hit the\r\nCTRL + SHIFT + F3 keys and a dialog box will be shown\r\nasking where the name for the range is. In the example shown, both cells\r\nB2 and C2 have been selected, with cell B2 containing the name to assign\r\nto cell C3\r\nCreate Names from SelectionIf all looks OK in the Create Names from Selection\r\ndialog box, click OK. Selecting cell C3 will shown\r\nData_Path in the Named Range drop down list as shown in the\r\nfirst image above.\r\nExtracting the Named Range\r\nvalue\r\nAlthough I mentioned above that the parameter can be created in one\r\nline of M code, we’ll look at the process of extracting named ranges\r\nfrom a worksheet.\r\n\r\nThe steps in the image above, produce these lines of M code.\r\nlet\r\n    Source = Excel.CurrentWorkbook(),\r\n    #\"Filtered Rows\" = Table.SelectRows(Source, each ([Name] = \"Data_Path\")),\r\n    #\"Removed Other Columns\" = Table.SelectColumns(#\"Filtered Rows\",{\"Content\"}),\r\n    #\"Expanded Content\" = Table.ExpandTableColumn(#\"Removed Other Columns\", \"Content\", {\"Column1\"}, {\"Column1\"}),\r\n    Column1 = #\"Expanded Content\"{0}[Column1]\r\nin\r\n    Column1\r\nWhat does this code do?\r\nThis will list all the named ranges, sheets names and tables.\r\nSource = Excel.CurrentWorkbook()\r\nThis step will filter the list of named ranges to the required\r\nvalue.\r\n#\"Filtered Rows\" = Table.SelectRows(Source, each ([Name] = \"Data_Path\")),\r\nRemoving the Name column from the table shown in the editor window,\r\nby selecting just the Content column.\r\n#\"Removed Other Columns\" = Table.SelectColumns(#\"Filtered Rows\",{\"Content\"})\r\nThis step expands the content in the row for the content column.\r\nClicking in a white space area, next to the word Table will\r\ngive a preview of the value(s) stored in that table.\r\n#\"Expanded Content\" = Table.ExpandTableColumn(#\"Removed Other Columns\", \"Content\", {\"Column1\"}, {\"Column1\"})\r\nTable ContentsColumn1 = #\"Expanded Content\"{0}[Column1]\r\nBy right-clicking in a white space area next to the word\r\nTable and select Drill Down to get to the\r\nvalue of the named range.\r\nA lot of steps to get to one value.\r\nCreate the Power Query\r\nParameter\r\nThe important parts of the M code above, that are needed to use as a\r\none line query are:\r\nExcel.CurrentWorkbook()\r\n\r\n[Name] = \"Data_Path\"\r\n\r\n\"Content\"\r\n\r\n{0}[Column1]\r\n\r\nThese values can be combined into one line:\r\nExcel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1]\r\nThe only part now needed is some meta data that lets Power Query know\r\nthat this query is actually a parameter.\r\nmeta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\nCombining these two sets of M code to create the final result.\r\nExcel.CurrentWorkbook(){[Name=\"Data_Path\"]}[Content]{0}[Column1] meta [IsParameterQuery=true, Type=\"Text\", IsParameterQueryRequired=false]\r\nUsing the Parameter\r\nTo use the parameter in a query, just replace any previously\r\nhard-coded path or file name. As the query contains the meta data values\r\nat the end, the value will also be available in any drop-down lists for\r\nparameters.\r\nUsing a parameterConclusion\r\nThis method of using named ranges from worksheets has reduced\r\ndevelopment time when creating automated excel workbooks.\r\nThere is also a method for storing many parameters in one query, but\r\nthat can be a post for another day.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-15-how-to-parameterise/./CreateParameter1.gif",
    "last_modified": "2022-08-15T18:05:02+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-14-2022-08-14-pq-zoom/",
    "title": "Zooming",
    "description": "Zooming the Power Query Editor Window",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-14",
    "categories": [
      "Excel",
      "Power Query",
      "Tips and Tricks"
    ],
    "contents": "\r\nA tip that is often forgotten about is how to zoom in and out when\r\nusing the Power Query Editor. The text showing the data table can appear\r\nsmall to those with visual difficulties. Even for those without\r\ndifficulties, the size of the text can prove problematic at times.\r\nTo increase the size of the text shown in the editor window, use the\r\nkey combinations of\r\nCTRL SHIFT + to zoom in\r\nCTRL SHIFT - to zoom out\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-14-2022-08-14-pq-zoom/./zoom.gif",
    "last_modified": "2022-08-14T16:19:56+01:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to GFC Learning",
    "description": "Welcome to my blog, GFC Learning.",
    "author": [
      {
        "name": "Graham Cox",
        "url": {}
      }
    ],
    "date": "2022-08-14",
    "categories": [],
    "contents": "\r\nExcel question? Problems with Power Query?\r\nHere I will try to answer some of the more obscure questions you may have about using MS Excel and Power Query, PowerPivot, DAX and using the Excel Data Model and throw some Visual Basic for Applications (VBA) into the mix.\r\n\r\n\r\n\r\nI have also recently been learning the programming language R. There will also be posts using R showing how I have been using it for data transformations and data visulisations.\r\n\r\nThis website was built completely in R using the distill package. Distill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/welcome/./logo.jpg",
    "last_modified": "2023-03-03T14:28:41+00:00",
    "input_file": "welcome.knit.md"
  }
]
